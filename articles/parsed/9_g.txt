The limitation of classical logic as a representation for human knowledge and reasoning is that its inference rule, modus ponena, is the analogue to human deductive reasoning, but for the most part everyday human reasoning seems to have significant non-deductive components. But while certain aspects of human reasoning (e.g.
inductive generalization and abductive explanation) seem to be substantially different from deduction, a certain class of reasoning, dubbed “default reasoning,” resembles deduction more closely. Thus it was thought that extensions to first-order logic might result in formal systems capable of representing the process of default reasoning.

While it is still not clear exactly what constitutes default ing, the phenomenon commonly manifests itself when we know conclusions should be drawn about typical situations or objects,  ‘This work was supported in part by ONR grant N00014-855I<-0301. Many thanks to Alex Kass and Yoav Shoham for discussing this work with us, and for reading drafts of the paper.

we must jump to the conclusion that an observed situation or object ia typical. For example, I may know that I typically meet with my advisor on Thursday afternoons, but I can’t deduce that I will actually have a meeting nezt Thursday because I don’t know whether next Thursday is typical. While certain facts may allow me to deduce that next Thursday is not typical (e.g. if I learn he will be out of town all next week), in general there will be no way for me to deduce that it ia. What we want to do in cases like this is to jump to the conclusion that next Thursday is typical based on two pieces of information: first that most Thursdays are typical, and second that we have no reason to believe that this one is not. Another way to express the same notion is to say that I know that I have meetings on typical Thursdays, and that the only atypical Thursdays are the ones that I know (can deduce) are atypical.

Research on nonmonotonic logics2, most notably by McCarthy (in (81 and [9]), McDermott and Doyle (in [12]) and Reiter (in [l4]) attacked the problem of extending first-order logic. in a way that captured the intuitive meaning of statements of the form “lacking evidence to the contrary, infer CX”or more generally “infer p from the inability to infer a.” But since that first flurry of research the area has developed in a strange way. On one hand the logics have been subjected to intense technical scrutiny (in the papers cited above, and also, for example, in Davis [2]) and have been shown to produce counterintuitive results under certain circumstances. At the same time we see in the literature practical representation problems such as story understanding (Charniak [1]), social convention in conversation (Joshi, Webber, and Weischedel [6]), and temporal reasoning (McDermott [11] and McCarthy [9]), in which default rules would aeem to be of use, but in these cases technical details of the formal systems are for the most part ignored.

The middle ground-whether the technical workings of the logics correctly bear out one’s intentions in representing practical defaultreasoning problems-is for the most part empty, though the work of Reiter, Etherington, and Criscuoio, in 131, [4], and elsewhere, is a notable exception. Logicians have for the most part ignored practical problems to focus on technical details, and “practitioners’ have used the default rules intuitively, with the hope (most often unstated) that the proof theory or semantics of the logics can eventually be shown to support those intuitions.

We explore that middle ground by presenting poral reasoning that involves default inference, nonmonotonic logics intended to represent that  *So called because of the property that inferences allowed by the logic may be disallowed as axioms are added. For example I may jump to the conclusion that next Thursday is typical, thus deduce that I will have a meeting. If I later come to find out that it is otypicd, I will have to retmcl that conclusion. In first-order logic the addition of new knowledge (axioms) to a theory can never diminish the deductions one can make from that theory, thus it is never necessary to retract conclusions.
3This sounds much more straightforward than it is: consider that the theorems of a logic are defined in terms of its inference rules, yet here we are trying to define an inference rule in terms of what is or is not a theorem.

then analyzing the resulting theory. Reasoning about time is an interesting application for a couple of reasons. First of all, the problem of representing the tendency of facts to endure over time (the “frame problem” of McCarthy and Hayes ]lO] or the notion of =persistence” in McDermott [ll]) has long been assumed to be one of those practical reasoning problems that nonmonotonic logics would solve. Second, one has strong intuitions about how the problem should be formalized in the three logics, and even stronger intuitions about what inferences should then follow, so it will be clear whether the logics have succeeded or failed to represent the domain correctly.

In the rest of the paper we discuss briefly some technical aspects of nonmonotonic logics, then go on to pose formally the problem of temporal projection. We then analyze the inferences allowed by the resulting theory and show that they do not correspond to what we intended when we wrote the axioms. Finally we point out the (unexpected) characteristics of the domain that the logics were unable to capture, and discuss proposed solutions to the problem.

Since we are considering the question of what inferences can be drawn from a nonmonotonic theory, we should look briefly at how inference is defined in these logics. We will concentrate on Reiter’s default logic and on circumscription, but the discussion and subsequent results hold for McDermott’s nonmonotonic logic as well.

Reiter in [14] defines a default theory as two sets of rules.
consists of sentences in first-order logic (and is usually as W), and the second is a set of default rules (referred Default rules are supposed to indicate what conclusions and are of the form  where (Y, p, and 7 are first-order sentences. The intended interpretation of this rule is “if you believe Q, and it’s consistent to believe p, then believe 7,” or, to phrase the idea more like an inference rule, “from a and the inability to prove +, infer 7.” (But recall our note above about the futility of trying to define inference in terms of inference.)  In order to discuss default inference we must introduce the concept of an extension-a set of sentences that “extend” the sentences in W according to the dictates of the default rules. A default theory defines zero or more extensions, each of which has the following properties: (1) any extension E contains W, (2) E is closed under (monotonic) deduction, and (3) E is faithful to the default rules.
By the last we mean that if there’s a default rule in the theory of the form y , and if a E E, and (-p) @ E, then 7 E E. The extensions of a default theory are all the minimal sets E that satisfy rthese three properties. Extensions can be looked upon as internally consistent and coherent states of the world, though the union of two extensions may be inconsistent.

Finding a satisfying definition of default inference--what sentences can be said to follow from a default theory-is tricky. Reiter avoids the problem altogether, focusing on the task of defining extensions and exploring their properties. He expresses the view that default reasoning is really a process of selecting one extension of a theory, then reasoning “within” this extension until new information forces a revision of one’s beliefs and hence the selection of a new extension.

This view of default reasoning, while intuitively appealing, is infeasible from a practical standpoint: there is no way of “isolating” a single extension of a theory, thus no procedure for enumerating or  testing theoremhood within an extension. So any definition of default reasoning based on discriminating among extensions is actually beyond the expressive power of default logic. Reiter does provide a proof procedure for asking whether a sentence is a member of any extension, but, as he points out, this is not a satisfying definition of inference since both a sentence and its negation may appear in different extensions.

Our view in this paper is that some notion of inference is necessary to judge the representational power of the logic. A logic that generates one intuitive extension and one unintuitive extension does not provide an adequate representation of the problem, since there is no way to distinguish between the two interpretations. For that reason we will define inference in the manner of McDermott’s logic: a sentence 5 can be inferred from a default theory jnst in case 6 is in every extension of that theory. (This definition is also consistent with circumscriptive inference as described in the next section.)  While there is no general procedure for determining how many extensions a given theory has, as a practical matter it has been noted that theories with “conflicting” default rules tend to generate multiple extensions. For example, the following default theory  has two rules that would have us jump to contradictory conclusions.
But note that applying one of the rules means that the other cannot be applied, since its precondition is not met. This default theory has two extensions: El = {Q(N), R(N), P(N)} and E2 = {Q(N), R(N), 1 P(N)} that correspond to the two choices one has in applying the default rules. (One interpretation of this theory reads Q as ‘Quaker,” R as “Republican,” P as “Pacifist,” and N as ‘Nixon.“) Thus the above theory entails only the sentences in W, plus tautologies (for example P(N) V -P(N)).

We are not claiming that this admission of multiple extensions is a fault or deficiency of the logic-in this particular example it’s hard to imagine how the logic could license any other conclusions. Our point is that when a theory generates multiple extensions it’s generally going to be the case that only weak inferences can be drawn. Further, if one extension captures the intended interpretation but there are other different extensions, it will not be possible to make only the intended inferences.

To describe inference rather vague: there (91 and elsewhere, ferences.

in circumscribed are several versions and we will not spend  theories we will have to be of the logic, defined in [8], time discussing these dif We will speak generally of predicate circumscription, in which the intent is to minimize the extension of a predicate (say P) in a set of first-order axioms. Using terms like those we used in describing default logic, we might say that when we circumscribe axioms over P we intend that “the only individuals for which P holds are those individuals for which P must hold,” or alternatively we might phrase it as ‘believe ‘not P’ by default.”  To circumscribe a set of axioms A over a predicate P one adds to A an axiom (the exact form of which is not important for our discussion) that says something like this: “any predicate P’ that satisfies the axioms A, and is at least as strong as P, is exactly as strong as P.” The intended effect is (roughly) that for any individual X7  To talk about circumscriptive inference, we should first note that since Circum(A, P) is a first-order theory we want to know what deductively follows, but we are interested in characterizing these deductions in terms of the original axioms A. In brief, the results are these: if a formula ‘p is a theorem of Circum(A, P) then cp is true in all models of A minimal in P (this property is called soundness), and if a formula cp is true in all models of A minimal in P then ‘p is a theorem of Circum(A, P) (this property is called completeness).
Completeness does not hold for all circumscribed theories, but it does hold in certain special cases-see Minker and Perlis [13].

Minimal models, the model-theoretic analogue to default-logic extensions, are defined as follows: a model M is minimal in P just in case there is no model M’ that agrees with M on all predicates ezcept for P, but whose extension of P is a subset of M’s extension of P.

As with default logic, there is no effective procedure for determining how many minimal models a theory has. And note that the converse of the soundness property says that if ‘p is not true in all models minimal in P it does not follow from Circum(A, P). So once again, if we have multiple minimal models, what we can deduce are only those formulas true in all of them. Because of the obvious parallels between extensions and minimal models (and “NM fixed points” in McDermott’s logic, which we will not discuss here), we will use the terms interchangeably when the exact logic or object doesn’t matter.

We obviously need some temporal representation to express these concepts, and we will use the situation calculus [lo]. We will thus speak about jucta holding true in situations. A fact syntactically has the form of a first-order sentence, and is intended to be an assertion about the world, such as SUNNY, LOADED(GlJN-35), or V x.HAPPY(xj. Situations are individuals denoting intervals of time over which facts hold or do not hold, but over which no fact changes its truth value. This latter property allows us to speak unambiguously about what facts are true or false in a situation. To say that a fact f is true in a situation s we assert T([ s), where T is a predicate and f and s are terms.

Events are things that happen in the world, and the occurence of an event may have the effect of changing the truth value of a fact. So we think of an event occuring in a situation and causing a transition to another situation-one in which the event’s effects on the world are reflected. The function RESULT maps a situation and an event into another situation, so if So is a situation and WAKEUP(JOHNj is an event, then RESULT(WAKEUP(JOHNj. So) is also a situationpresumably the one resulting from JOHN waking up in situation So.
We might then want to state that JOHN is awake in this situation:  T( AWAKE(JOHNj. RESULT( WAKEUP(JOHNj, or more generally we might state that  A problem arises when we try to express the notion that facts to stay true from situation to situation as irrelevant events For example, is JOHN still awake in the state SZ, where  S2 = RESULT(EAT-BREAKFAST(JOHNj, RESULT(WAKEUP(JOHNj. So))?  Intuitively we would like to assume so, because it’s typically that eating breakfast does not cause one to fall asleep.
the above axioms there is no way to deduce  T( AWAKE(JOHNj. &j.
We could add an axiom to the effect that if one is awake in a situation then one is still awake after eating breakfast, but this seems somewhat arbitrary (and will occasionally be false). And in any reasonable description of what one might do in the course of a morning there would have to be a staggering number of axioms expressing something like “if fact f is true in a situation s, and e is an event, then f is still true in the situation RE.SULT(e. sj.” McCarthy and Hayes (in [lo]) ca 11axioms of this kind “frame axioms,” and identified the “frame problem” as that of having to explicitly state many such axioms. Deductive logic forces us into the position of assuming that an event occurence may potentially change the truth value of all facts, thus if it does not change the value of a particular fact in a particular situation we must explicitly say so. What we would like to do is assume just the opposite: that most events do not affect the truth of most facts under most circumstances.

Intuitively we want to solve the frame problem by assuming that in general an event happening in a situation is irrelevant to a fact’s truth value in the resulting situation. Or, to make the notion a little more precise, we want to assume “by default” that  T(t sj I T(t RESULT(e, sjj for all facts, situations, and events. But note the quotes: the point of this paper is that formalizing this assumption is not as straightforward as the phrase might lead one to believe.

McCarthy’s proposed solution to the frame problem (described in 191)involves extending the situation calculus a little, to make it what he calls a “simple abnormality theory.” We state that all ‘normal” facts persist across occurences of ‘normal” events:  V f. e. s. T(t sj A 7 AB(f e. sj I T(t RESULT(e. sjj where AB(f, e, sj is taken to mean ‘fact f is abnormal with respect to event e occuring in state s,” or, “there’s something about event e occuring in state s that causes fact f to stop being true in RESULT(e.s).” We would expect, for example, that it would be true that  V p, s. AB(AWAKE(p), GOTOSLEEP(pj.
we would have to add a specific axiom  Of course we still haven’t solved the frame problem, since we haven’t provided any way to deduce 7 AB(te,sj for most facts, events, and situations. As an alternative to providing myriad frame axioms of this form, McCarthy proposes that we circumscribe over the predicate AB, thus “minimizing” the abnormal temporal individuals. The question is whether this indeed represents what we intuitively mean by saying that we should ‘assume the persistence of facts by default,” or “once true, facts tend to stay true over time.”  As an illustration of what we can infer from a very simple situationcalculus abnormality theory, consider the axioms of Figure 1. For simplicity we have restricted the syntactic form of facts and events to be propositional symbols, so the axioms can be interpreted as referring to a single individual who at any point in time (situation) can be either ALIVE or DEAD and a gun that can be either LOADED or UNLOADED. At some known situation So the person is alive (Axiom l), and the gun becomes loaded any time a LOAD event happens (Axiom 2). Axiom 3 says that any time the person is shot with a loaded gun he becomes dead, and furthermore that being shot with a loaded gun is abnormal with respect to staying alive. Or to use our definition from above: there is something about a SHOOT event occuring in a situation in which the gun is loaded that causes the fact ALIVE to stop being true in the situation resulting from the shot. Axiom 4 is just the assertion we made above that %ormal” facts persist across the occurence of “normaln events.

~(ALIVE. 54-J V s. T(LOADED. RESULT(LOAD. s)) V s. T(LOADED. s) > AB(ALIVE. SHOOT, s) A T(DEAD. RESULT(SHOOT. s)) V 6 e, s. T(t s) A 7 AB(t e. S)I T(t RESULT(e. s))  What, then, can be deduced from the (circumscribed) abnormality theory? It’s fairly easy to verify that the two models we have presented are the only two minimal in AB, so the theorems of Circum(A, AB) are those common to those two models. So we can deduce that ALIVE and LOADED are true in Sr, that ALIVE is true in $,, but we ca,n say nothing about what is true in &except for statements like T(ALIVE, Ss) v T(DEAD. 5). What we can deduce from Circum(A, AB) is therefore considerably weaker than what we had intended.

The question now arises: how dependent is this result on the specific problem and formulation we just presented? Does the same problem arise if we use a different default logic or a different temporal formalism?  (where any individual may be substituted for < e, and s). Recall that extensions are defined proof-theoretically instead of in terms of models, so we must translate the minimal models shown in Figure 2 (b and c) into sets of sentences; the question becomes whether the following sets are default-logic extensions:  T(ALIVE. So) 7 AB(ALIVE. LOAD, So) T(A Ll VE. SJ T(LOA DED. SI) - AB(ALIVE. WAIT, S1) 7 AB(LOADED. WAIT. SI) T(ALIVE, S2) T(LOA DED, SJ AB(ALIVE. SHOOT, S2) 7 AB(LOADED. SHOOT, S2) T(DEA D, S3) T(LOA DED. S3)  T(A LIVE. So) 7 AB(ALIVE, T(ALIVE. S1) T(LOADED.
7 AB(ALIVE.
AB(LOADED.
T(ALIVE, &)  Nor is the situation calculus to blame: in a previous paper [5] we use a simplified version of McDermott’s temporal logic and show that the same problem arises, again for all three default logics. In the next section we will show what characteristics of temporal projection lead to the multiple-extension problem, and why it appears that the three default logics are inherently unable to represent the domain correctly.

We noted above that default-logic theories often generate multiple extensions. But characteristic of all the usual examples, like the one we used in Section 2, is the fact that the default rules of these theories were mutually exclusive: the application of one rule rendered other rules inapplicable by blocking their preconditions.

Thus it comes as somewhat of a surprise that the temporal projection problem should exhibit several extensions. How can there be conflicting rules in the same way we saw above when our theory has  only a single default rule? It turns out that conflict between rulG arises in our domain in a different, more subtle, manner. To see how, recall how we built the first minimal model (that of Figure 2b). The idea was that we assumed one ‘normality,” then went on to make all possible deductions, then assumed another “normality,” and so on.
The picture looks something like this:  A B(LOA DED, WAIT, SI) a T(LOADED, Sz) j AB(ALIVE, SHOOT, S2)  where the conflict to notice is that as a result of assuming mality” we could deduce an abnormality. The same thing when we build the model in Figure 2c, except the picture this instead (reading from right to left):  AB(LOADED. WAIT, SI) s= . . . -e 7 AB(ALIVE. SHOOT. 52).

The only difference between the two models is that in the first case we started at the (temporally) earliest situation and worked our way forward in time, and in the second case we started at the latest point and worked our way backward in time. Another way to express the idea is that in the first model we always picked the Uearliest possible” ([ e, S) triple to assume “normal” and in the second model we always picked the latest.

So the class of models we want our logic to select is not the “minimal models” in the set-inclusion sense of circumscription, but the “chronologically minimal” models (a term due to Yoav Shoham): those in which normality assumptions are made in chronological order, from earliest to latest, or, equivalently, those in which abnormality occurs as late as possible.

(In a richer temporal formalism the criterion chronological minimality might not be the right one. If several years had lapsed between the WAIT and the SHOT, for example, it would be reasonable to assume that the gun was no longer loaded. But chronological minimality does correctly represent our simple notion of persistence: that facts tend to stay true (forever) unless they are “clipped” by a contradictory fact.)  There appears to be no way represent this criterion, either in published versions of circumscription6 or in the logics of Reiter or McDermott. The concept of minimality in circumscription is intimately bound up with the notion of set inclusion, and chronological minimality cannot be expressed in those terms. As far as Reiter and McDermott’s logics go, what we need is some way to mediate application of default rules in building extensions or fixed points, which is beyond the expressive power of (Reiter’s) default rules or of NML sentences involving the M operator.

Two lines of work have been proposed as solutions to this problem. Yoav Shoham in 1151 presents a logic that directly addresses the problem of representing causation in terms of “time flowing forward.? Rather than trying to extend existing nonmonotonic logics so that they capture this new minimality criterion’he instead starts with a precise description of the chronologically minimal models. He then demonstrates that when a certain restricted class of first-order theories are minimized with respect to how much is known about each situation (instead of minimizing what is true in each situation) the resulting theory has a unique chronologically minimal model.
While Shoham’s logic handles the specific case of causal or temporal  6These include predicate circumscription and joint circumscription [8], formula circumscription and prioritized circumscription [9]. But see the note on pointwise circumscription below.

not an answer to the question between default reasoning  A second proposal, due to Vladimir Lifschitz in [7], involves a reformulation of and extension to predicate circumscription called pointwise circumscription, in which one minimizes a predicate one point at a time (in our example a point would be a (fact, event, situation) triple). The order in which points are minimized is specified by an object-language formula that can express the concept of “temporally earlier” and “temporally later.* Thus one is able to say something to the effect “minimize abnormalities, but favoring chronologically earlier ones.” Pointwise circumscription contains predicate circumscription as a special case, and has been shown to solve a simple example of interacting defaults that we presented in PI*  But what benefits do we realize from these new, more expressive, more complex versions of circumscription? The problem is that the original idea behind circumscription, that a simple, problemindependent extension to a first-order theory would “minimize” predicates in just the right way, has been lost along the way. Instead, a complex, problem-specific axiom must be found to rationalize a set of inferences which must themselves be justified on completely separate grounds. The real theory of reasoning is the minimality criterion. In this example it was Shoham’s chronological minimality; for other cases of default reasoning there will be other criteria for adding deductively unwarranted conclusions to a theory. It contributes little to our understanding of the problem that these criteria can be expressed as a second-order circumscription axiom; the criteria are justifying the axiom rather than the other way around.

The situation might be different if the second-order axiom were ‘productive,” that is, if further, perhaps unforeseen conclusions could be drawn from it, mechanically or otherwise. But it can be very hard to characterize the consequences of the circumscription axioms for a reasonably large and complex theory, and when the consequences are understood, they may not be at all what we intended. The upshot is that no one really wants to know what follows from circumscription axioms; they usually wind up as hopefully harmless decorations to the actual theory.

We have presented a problem in temporal reasoning-causal or temporal projection-that involves defeasible inference of the sort normally associated with nonmonotonic logics. But upon writing axioms that describe temporal projection in an intuitive way, we found that the inferences licensed by the logics did not correspond to our intentions in writing the axioms. There seem to be two reasons for this: that conflicting default rule instances lead to unexpected multiple fixed points (minimal models), and that our preference of one extension over another (our criterion for minimality) depends on an ordering of individuals that cannot be expressed by circumscribing over any predicate or set of predicates, or by the default rules in the other nonmonotonic logics.

At this point we need to re-evaluate the relationship between nonmonotonic logics and human default reasoning. We can no longer engage in the logical “wishful thinking” that led us to claim that circumscription solves the frame problem [9], or that “consistent’ is to be understood in the normal way it is construed in nonmonotonic logic.[l]” From a technical standpoint, there is no “normal way” to understand the M operator, or the Reiter default rules, or a theory circumscribed over some predicate, apart from the proof- or model theory of the chosen logic.

The term “consistent,” has too often used informally by researchers (e.g. in [6]) as if it had an intuitive and domain-independent meaning. \n7e have shown that in at least one case a precise definition  of the term is much more complex than intuition would have us believe, and that the definition is tightly bound up with the problem domain. As such, the claim implicit in the development of nonmonotonic logics-that a simple extension to classical logic would result in the power to express an important class of human nondeductive reasoning-is certainly called into question by our result.

Eugene “Motivation Analysis, Abductive Non-Monotonic Equality”, Cognitive,Science,  “A Temporal Logic for Reasoning About Cognitive Science, vol. 6 (1982), pp. lOl-