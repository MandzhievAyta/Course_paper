Incorporating $ltering techniques in a fuzzy linguistic multi-agent model for information gathering on the web  The networked world contains a vast amount of data. The exponential increase in Web sites and Web documents is contributing to that Internet users not being able to $nd the information they seek in a simple and timely manner. Users are in need of tools to help them cope with the large amount of inofrmation available on the Web [ 21,22]. Therefore, techniques for searching and mining the Web are becoming increasing vital. Two important techniques that have been addressed in improving the information access on the Web are related to intelligent agents and information ltering.
Intelligent agents applied on the Web deal with the information gathering process assisting Internet users to $nd the $ttest information to their needs [ 3,9,20,32]. Usually, several intelligent agents (e.g.
interface agent, information discovery agent) organized in distributed architectures take part in the  information gathering activity [3,8,9,20,25]. The problem is the design of appropriate communication protocols among the agents. The great variety of representations and evaluations of the inofrmation in the Internet is the main obstacle to this communication, and the problem becomes more noticeable when users take part in the process. This reveals the need of more Jexibility in the communication among agents and between agents and users [7,31–33]. To solve this problem we presented in [6,7,12] di>erent distributed intelligent agent models based on fuzzy linguistic information. Using di>erent fuzzy linguistic approaches [13,14,34], in [6,7,12] we proposed to introduce and handle Jexible information by means of linguistic labels, and in such a way, improving communication processes.
Another promising direction to improve the information access on the Web concerns the way in which it is possible to $lter the great amount of information available across the Web. Information $ltering is a name used to describe a variety of processes involving the delivery of inofrmation to people who need it. Operating in textual domains, ltering systems or recommender systems evaluate and $lter the great amount of inofrmation available on the Web (usually, stored in HTML or XML documents) to assist people in their search processes [27]. Traditionally, these systems have fallen into two main categories [26]. Content-based ltering systems $lter and recommend the information by matching user query terms with the index terms used in the representation of documents, ignoring data from other users. These recommender systems tend to fail when little is known about user information needs, e.g. as happens when the query language is poor. Collaborative ltering systems use explicit or implicit preferences from many users to $lter and recommend documents to a given user, ignoring the representation of documents. These recommender systems tend to fail when little is known about a user, or when he/she has uncommon interests [26]. Several researchers are exploring hybrid content-based and collaborative recommender systems to smooth out the disadvantages of each one of them [ 1,4,10,26]. Applications of hybrid-based recommender systems on the Web include search tools such as Google (www.google.com) and Inquirus 2 (inquirus.nj.nec.com/i2/inq2.pl) that combines results of both content searches and collaborative recommendations. Recommender systems employing information $ltering techniques often do so through the use of information $ltering agents [29]. Operating in the domain of Usenet news, NewT [ 24] employs a vector-space based genetic algorithm to learn which articles should be selected an which should not. RE:Agent [2] use learning techniques to classify e-mail based on a user’s prior actions. Finally, Amalthaea [25] is a multi-agent system for recommending Web sites.
In this paper, we present a new fuzzy linguistic multi-agent model for information gathering on the Web that uses di>erent information $ltering techniques to improve retrieval issues. We design it by using a 2-tuple fuzzy linguistic approach [14,15] as a way to endow the retrieval process with a higher Jexibility, uniformity and precision. As we did in [ 6], the communication of the evaluation of the retrieved information among the agents is carried out by using linguistic information represented by the 2-tuple fuzzy linguistic representation. The main novelty of this multi-agent model is that it combines both content-based $ltering and collaborative $ltering techniques. Users represent their information needs by means of linguistic multi-weighted queries [17] and providing an information need category (medicine, decision making, economy). The multi-weighted queries are composed of terms which are weighted simultaneously by means of both linguistic threshold weights and linguistic relative importance weights. To exploit user preferences the multi-agent model incorporates two new elements in its architecture: (i) a content-based information ltering agent that $lters the documents by mean of a matching function used to model the threshold weights, and (ii) a collaborative ltering  agent that $lters and recommends documents related to information need category according to the evaluation judgements previously expressed by other users.
The paper is structured as follows. Section 2 reviews the 2-tuple fuzzy linguistic representation.
Section 3 presents the new fuzzy linguistic multi-agent model based on information $ltering techniques. Section 4 presents an example for illustrating our proposal. Finally, some concluding remarks are pointed out.

The use of Fuzzy Sets Theory has given very good results for modelling qualitative information [34]. It is a technique that handles fuzziness and represents qualitative aspects as linguistic labels by means of “linguistic variables”, that is, variables whose values are not numbers but words or sentences in a natural or arti$cial language.
The 2-tuple fuzzy linguistic approach was introduced in [14–16] to overcome the problems of loss of inofrmation of other ufzzy linguistic approaches [ 11,13,34]. Its main advantage is that the linguistic computational model based on linguistic 2-tuples can carry out processes of computing with words easier and without loss of inofrmation.

2.1. The concept of symbolic translation and 2-tuple representation model  Let S = {s0; : : : ; sg} be a linguistic term set with odd cardinality (g + 1 is the cardinality of S and usually is equal to 7 or 9), where the mid term represents an assessment of approximately 0.5 and with the rest of the terms being placed symmetrically around it. We assume that the semantics of labels is given by means of triangular membership ufnctions represented by a 3-tuple ( a; b; c) and consider all terms distributed on a scale on which a total order is de$ned si6sj ⇔ i6j. An example may be the following set of seven terms (Fig. 1):  s0 = Null(N ) = (0; 0; 0:17); s1 = VeryLow(VL) == (0; 0:17; 0:33);  s2 = Low(L) = (0:17; 0:33; 0:5); s3 = Medium(M ) = (0:33; 0:5; 0:67);  s4 = High(H ) = (0:5; 0:67; 0:83); s5 = VeryHigh(VH ) = (0:67; 0:83; 1);  Fig. 1. A set of seven linguistic terms with its semantics.

In this fuzzy linguistic context, if a symbolic method [11,13] aggregating linguistic information obtains a value ∈ [0; g], and ∈= {0; : : : ; g}, then an approximation function is used to express the result in S.

De nition 1 (Herrera and Martinez [14]). Let be the result of an aggregation of the indexes of a set of labels assessed in a linguistic term set S, i.e., the result of a symbolic aggregation operation, ∈ [0; g]. Let i = round( ) and = − i be two values, such that, i ∈ [0; g] and ∈ [−0:5; 0:5) then is called a Symbolic Translation.

Roughly speaking, the symbolic translation of a linguistic term, si, is a numerical value assessed in [−0:5; 0:5) that supports the “di>erence of inofrmation” between a counting of inofrmation ∈ [0; g] obtained after a symbolic aggregation operation and the closest value in {0; : : : ; g} that indicates the index of the closest linguistic term in S (i = round( )).
The 2-tuple fuzzy linguistic approach is developed from the concept of symbolic translation by representing the linguistic information by means of 2-tuples (si; i), si ∈ S and i ∈ [−0:5; 0:5):  • si represents the linguistic label of the inofrmation, and • i is a numerical value expressing the value of the translation rf om the original result closest index label, i, in the linguistic term set (si ∈ S).
This model de$nes a set of transformation functions between numeric values and 2-tuples.

De nition 2 (Herrera and Martinez [14]). Let S = {s0; : : : ; sg} be a linguistic term set and ∈ [0; g] a value representing the result of a symbolic aggregation operation, then the 2-tuple that expresses the equivalent information to is obtained with the following function:  where round(·) is the usual round operation, si has the closest index label to “ ” and “ ” is the value of the symbolic translation.

In [14] we show that there exists −1, such that, from a 2-tuple (si; ) it returns its equivalent numerical value ∈ [0; g] ⊂ R, which is obtained as −1(si; ) = i + . On the other hand, it is obvious that the conversion of a linguistic term into a linguistic 2-tuple consists of adding a symbolic translation value of 0 : si ∈ S ⇒ (si; 0).

The 2-tuple linguistic computational model is de$ned by presenting the comparison of 2-tuples, a negation operator and aggregation operators of 2-tuples.
1. Comparison of 2-tuples: The comparison of linguistic inofrmation represented by 2-tuples is carried out according to an ordinary lexicographic order. Let (sk ; 1) and (sl; 2) be two 2-tuples,  with each one representing a counting of inofrmation:  • If k¡l then (sk ; 1) is smaller than (sl; 2) • If k = l then  1. if 1 = 2 then (sk ; 1) and (sl; 2) represent the same information, 2. if 1¡ 2 then (sk ; 1) is smaller than (sl; 2), 3. if 1¿ 2 then (sk ; 1) is bigger than (sl; 2).

2. Negation operator of 2-tuples: This operator is de$ned as follows:  3. Aggregation operators of 2-tuples: The aggregation of information consists of obtaining a value that summarizes a set of values, thereofre, the result of the aggregation of a set of 2-tuples must be a 2-tuple. In the literature we can $nd many aggregation operators which allow us to combine the information according to di>erent criteria. Using functions and −1 that transform without loss of information numerical values into linguistic 2-tuples and viceversa, any of the existing aggregation operator can be easily extended for dealing with linguistic 2-tuples. Some examples are  • Arithmetic Mean. The arithmetic mean is a classical numerical aggregation operator. Its equivalent operator, for linguistic 2-tuples, is de$ned as,  De nition 3. Let x = {(r1; 1); : : : ; (rn; n)} be a set of linguistic 2-tuples, the 2-tuple arithmetic mean xe is computed as,  • Weighted average operator. The weighted average is used when di>erent values xi have a di>erent importance in the nature of the variable x. To do so, each value xi has a weight associated to it, wi, indicating its importance in the nature of the variable. The equivalent operator ofr linguistic 2-tuples is de$ned as:  De nition 4. Let x = {(r1; 1); : : : ; (rn; n)} be a set of linguistic 2-tuples and their associated weights. The 2-tuple weighted average xw is  • Linguistic weighted average operator. This operator is an extension of xw assuming that the weights are expressed by means of linguistic 2-tuples.

De nition 5. Let x = {(r1; 1); : : : ; (rn; n)} be a set of linguistic 2-tuples and W = {(w1; 1w); : : : ; (wn; nw)} be their linguistic 2-tuple associated weights. The 2-tuple linguistic weighted average xlw is  xlw[((r1; 1); (w1; 1w)) : : : ((rn; n); (wn; nw))] =  3. A fuzzy linguistic multi-agent model based on information ltering techniques  In this section we present a new fuzzy linguistic multi-agent model based on a 2-tuple fuzzy linguistic approach. It is developed from the multi-agent model de$ned in [6]. We propose to improve the performance of that by incorporating in its architecture both content-based $ltering and collaborative $ltering techniques.

3.1. Architecture of the multi-agent model presented in [6]  A multi-agent system is one in which a number of agents cooperates and interact with each other in a complex and distributed environment. In a typical multi-agent system the agents work together to achieve a global objective based on distributed data and control. Multi-agent systems have been widely used in Web applications [5,23,25,29]. In [9,20] a detailed study on multi-agent system is presented.
In [30] a distributed multi-agent model for the information gathering is de$ned. This model develops the retrieval activity by considering $ve action levels: internet users, interface agents, task agents, information agents and information sources. Using this model, in [6] we de$ned a fuzzy linguistic distributed multi-agent model that uses linguistic 2-tuples to carry out the communication processes among the agents. In such a way, we incorporate in the retrieval process a higher degree of Jexibility to carry out the inof rmation interchange, but in a precise way. This model presents a hierarchical architecture with $ve activity levels:  • Level 1: Internet user, which looks for Web documents on the Internet by means of a weighted query where a set of terms {t1; t2; : : : ; tm} related to the desired documents is speci$ed together with their respective linguistic relative importance degrees {p1; p2; : : : ; pm}, pi ∈ S.
• Level 2: Interface agent (generally one for user), that communicates the user weighted query to the task agent, and $lters the retrieved documents from task agent in order to give the user those ones that better satisfy his/her needs.
• Level 3: Task agent (generally one for interface agent), that communicates the terms of user query to the information agents, and get those documents from every information agent that better ful$ll the weighted query, fusing them and resolving the possible conJicts among the information agents.
• Level 4: Information agents, which receive the terms of user query rfom the task agent and look for the documents in the information sources. Then, the task agent receives from every information agent h a set of documents and their relevance ( Dh; Rh), where every document djh has an associated degree of relevance rjh ∈ [0; 1] ( j = 1; : : : ; #(Dh)). It also receives a set of  linguistic degrees of satisafction C h = {c1h; c2h; : : : ; cmh}, cih ∈ S × [−0:5; 0:5) of this set of documents with regard to every term of the query.
• Level 5: Information sources, consisting of all data sources within the Internet, such as databases and information repositories.

The architecture of this model in the case of a single user scheme is represented in Fig.

3.2. Architecture of fuzzy linguistic multi-agent model based on information ltering techniques  As it is known, a promising direction to improve the e>ectiveness of search engines concerns the way in which it is possible to “$lter” the great amount of inofrmation available across the Internet [19]. As it was said at the beginning, the so-called recommender systems are useful tools to carry out the evaluation and $ltering activities on the Web [27]. The combined use of recommender systems together with search multi-agent systems has given very good issues on the Web [2,24,25,29].
Then, our idea consists of applying the use of recommender systems in the multi-agent model presented in [6] to improve its performance. The incorporation of recommender systems in its architecture increases its information $ltering possibilities on the Web. To do so, we present a new fuzzy linguistic multi-agent model that combines in its activity the two more important existing $ltering techniques, content-based $ltering and collaborative $ltering [ 26,27]. It integrates in its architecture two new levels: the level of the content-based ltering agents and the level of collaborative ltering agent. Furthermore, the users’ expression possibilities are increased. Users specify their information needs by means of both a linguistic multi-weighted query and an inofrmation need category. Multiweighted query languages allow user to express better their ideas of concept of relevance and, in such a way, information retrieval systems have more possibilities to $nd their desired documents [17,18]. Each term of a user query can be weighted simultaneously by two linguistic weights. The $rst weight is associated with a classical threshold semantics and the second one with a relative importance semantics. By associating threshold weights with terms in a query, the user is asking to see all the documents suSciently related to the topics represented by such terms. The threshold weights are used by the content-based $ltering agents to carry out a $rst $ltering of documents to retrieve. By associating relative importance weights to terms in a query, the user is asking to see all documents whose content represents the concept that is more associated with the most important terms rather than with the least important ones. The relative importance weights are used by the task agent to determinate the number of documents to be retrieved rfom each content-based $ltering agent. The information need category represents the interest topic of the user’s information need, e.g.,“information retrieval”, “medicine”, “decision making”. Previously, a list of information categories available to users must be established. The information need category is used by the collaborative $ltering agent to carry out a second $ltering of documents that are retrieved and shown to the users de$nitively.
This new multi-agent model presents a hierarchical architecture that contains 7 activity levels (see Fig. 3):  • Level 1: Internet user, which expresses his/her information needs by means of a linguistic multi-weighted query {(t1; p11; p12); (t2; p1; p22); : : : ; (tm; pm1; pm2)}, pi1; pi2 ∈ S and an information need 2 category Ai ∈ {A1; : : : ; Al}. He also provides his/her identity ID (e.g. e-mail).

• Level 2: Interface agent (one for user), that communicates the user multi-weighted query, the information need category and the user identity to the collaborative $ltering agent, $lters the retrieved documents from collaborative $ltering agent to give to the user those that satisfy better his/her needs, and $nally, informs the collaborative $ltering agent on set of documents used by user to satisfy his/her information needs DU .

• Level 3: Collaborative ltering agent (one for interface agent), that communicates the user multiweighted query to the task agent, receives the more relevant documents chosen by the task agent, retrieves the recommendations on such documents from a collaborative recommendation system using the information need category expressed by the user RCAi = {RC1Ai ; : : : ; RCvAi }RCjAi ∈ S × [−0:5; 0:5), $lters the documents by recalculating their relevance using these recommendations, and communicates these documents together with their new relevance degrees to the interface agent. Later, it carries out the tasks to update in the collaborative recommendation system the recommendations on the documents used by the user, i.e., it invites user to provide a recommendation rcy on each chosen document dU y ∈ DU and this recommendation is stored in the collaborative recommendation system together with the recommendations provided by other users that used dyU .
• Level 4: Task agent (one for collaborative $ltering agent), that communicates the terms of user query together with their respective threshold weights to the content-based $ltering agents, and $lters documents provided by content-based $ltering agents by getting those documents from every content-based $ltering agent that ful$ll better the weighted query, fusing them and resolving the possible conJicts among the content-based $ltering agents.
• Level 5: Content-based ltering agents (one for information agent). Each content-based $ltering agent communicates the terms of user query to its respective inofrmation agent and $lters the relevant documents provided by its information agent by recalculating their relevance using the threshold weights. Then, the task agent receives from every content-based $ltering agent h a set of documents and their relevance ( Dh; RN h), where every document djh has associated a linguistic degree of relevance expressed in linguistic 2-tuples rnjh ∈ S × [−0:5; 0:5) ( j = 1; : : : ; #(Dh)). It also receives a set of linguistic degrees of satisafction C h = {c1h; c2h; : : : ; cmh}, cih ∈ S × [−0:5; 0:5) of this set of documents Dh with regard to every term of the query ti.
• Level 6: Information agents, which receive the terms of user query rfom the content-based $ltering agents and look for the documents in the information sources. Then, each content-based $ltering agent h receives from its respective information agent h the set of relevant documents that it found through information sources Dh and their relevance Rh, where every document djh has an associated degree of relevance rjh ∈ S × [−0:5; 0:5) ( j = 1; : : : ; #(Dh)).
• Level 7: Information sources.

3.3. Operation of fuzzy linguistic multi-agent model based on ltering agents  The activity of multi-agent model presented in the above subsection is composed of two phases: 1. Retrieval phase: This $rst phase coincides with the information gathering process developed by the multi-agent model itself, i.e., this phase begins when a user speci$es his/her query and $nishes when he/she chooses his/her desired documents among the relevant documents retrieved and provided by the system.
2. Feedback phase: This second phase coincides with the updating process of collaborative recommendations on desired documents existing in the collaborative recommender system, i.e., this phase begins when the interface agent informs the documents chosen by the user to the collaborative ltering agent and $nishes when the recommender system recalculates and updates the recommendations of the desired documents.

3.3.1. Retrieval phase The information gathering process of multi-agent model is carried out as follows:  • Step 1: An Internet user expresses his/her information needs by means of a linguistic multi-weighted query {(t1; p11; p12); (t2; p21; p22); : : : ; (tm; pm1; pm2)}, pi1; pi2 ∈ S and an information need category Ai chosen from a list of information need categories {A1; : : : ; Al} provided by the system. The system also requires the user’s identity ID. All this information is given by the user to the interface agent.
• Step 2: The interface agent gives the linguistic multi-weighted query together with the information need category to the collaborative ltering agent.
• Step 3: The collaborative ltering agent gives the linguistic multi-weighted query to the task agent.
• Step 4: The task agent communicates the terms of the query {t1; t2; : : : ; tm} together with their respective linguistic threshold weights {p11; p21; : : : ; pm1}, pi1 ∈ S to all the content-based ltering agents to which it is connected.
• Step 5: Each content-based ltering agent h makes the query to its respective information agent h and gives it the terms of the query {t1; t2; : : : ; tm}.
• Step 6: All the information agents that have received the query, look for the information that better satis$es it in the information sources, and retrieve from them the documents. We assume that the documents are represented in the information sources using an index term based representation as in Information Retrieval [17,18,28]. Then, there exists a $nite set of index terms T = {t1; : : : ; tl} used to represent the documents and each document dj is represented as a fuzzy subset  where F is any numerical indexing function that weighs index terms according to their signi$cance in describing the content of a document. F(dj; ti) = 0 implies that the document dj is not at all about the concept(s) represented by index term ti and F(dj; ti) = 1 implies that the document dj is perfectly represented by the concept(s) indicated by ti.
• Step 7: Each content-based ltering agent h receives from its respective information agent h a set of documents and their relevance ( Dh; Rh) ordered decreasingly by relevance. Every document djh has associated a linguistic degree of relevance rjh ∈ S × [−0:5; 0:5), which is calculated as  rjh = xe[ (g · F(djh; t1)); : : : ; (g · F(djh; tm))] =  g + 1 being the cardinality of S. Each content-based ltering agent h $lters documents received from its respective information agent h by recalculating their relevance by means of a linguistic matching function  which is de$ned to model the semantics of threshold weights associated with the query terms. Different content-based ltering agents can have di>erent threshold matching functions. For example,  some linguistic matching functions that we can use are:  Then, each content-based ltering agent h calculates a new set of relevance degrees RN h = {rnjh; j = 1; : : : ; #(Dh)} characterizing the documents Dh, which is obtained as  rnjh = xe[eh( (g · F(djh; t1)); p11); : : : ; eh( (g · F(djh; tm)); pm1)]  • Step 8: The task agent receives from every content-based ltering agent h a set of documents and their new relevance (Dh; RN h). It also receives a set of linguistic degree of satisafction C h = {c1h; c2h; : : : ; cmh}, cih ∈ S × [−0:5; 0:5) of Dh with regard to every term of the query, which is calculated as  cih = xe[eh( (g · F(dh1; ti)); pi1); : : : ; eh( (g · F(dh#(Dh); ti)); pi1)]  .h = xlw[(c1h; (p12; 0)); : : : ; (cmh; (pm2; 0))]:  Then, the task agent selects the number of documents to be retrieved rf om each ltering agent h. To do so, it applies the following three steps:  • Step 8.1: The task agent orders Dh with respect to the new relevance RN .
• Step 8.2: The task agent aggregates through a 2-tuple linguistic weighted average operator, for example xlw, both the satisfaction of the query terms C h and the relative importance weights that p2; i = 1; : : : ; m}. In such a way, it obtains a satisfaction the user assigned to the query terms, { i degree .h ∈ S × [−0:5; 0:5) for each content-based ltering agent h, which is computed as follows:  • Step 8.3: To gather the better documents from content-based ltering agents, the task agent selects a number of documents k(Dh) from every content-based ltering agent h being proportional to its respective degree of satisafction .h [6]:  where Psh = −1(.h)= in=1 −1(.h) is the probability of selection of the documents rfom based ltering agent h.
• Step 9: The collaborative ltering agent receives from the task agent a list ofdocuments DV = {d1V ; : : : ; dvV } ordered with respect to their relevance RV , such that  1. rjV ¿rjV+1, 2. for a given document djV ∈ DV there exists a h such that djV ∈ Dh and rjV ∈ RN h, and 3. #(DV ) = v6 in=1 k(Di).

Then, collaborative ltering agent $lters the documents provided by the task agent using the recommendations on such documents provided by other users in previous searches which are stored in a collaborative recommender system. This is done in the following steps:  • Step 9.1: The collaborative ltering agent asks collaborative recommender system the recommendations existing on DV associated with the information need category Ai expressed by the user and retrieves them,  RCAi = {RC1Ai ; : : : ; RCvAi }RCjAi ∈ S × [−0:5; 0:5):  • Step 9.2: The collaborative ltering agent $lters the documents by recalculating their relevance using these recommendations RCAi . Then, for each document djV ∈ DV a new linguistic relevance  degree rjNV is calculated from rjV and RCjAi by means of the 2-tuple weighted operator xw de$ned in De$nition 4  rjNV = xw(rjV ; RCjAi ); using for example the weighting vector W = [0:6; 0:4]:  • Step 10: The interface agent receives from the collaborative ltering agent a list of documents DW = {d1W ; : : : ; dwW } ordered with respect to their relevance RW , such that:  1. rjW ¿rjW+1, 2. for a given document djW ∈ DW there exists a i such that djW = diV and rjW = riNV , and 3. #(DW ) = w6v = #(DV ).

Then, the interface agent $lters these documents in order to give to the user only those documents that ful$ll better his/her needs, which we call Df. For example, it can select a $xed number of documents K and to show the K best documents.

3.3.2. Feedback phase This phase is related to the activity developed by the collaborative recommender system once user has taken some of documents retrieved by the multi-agent system.
In the collaborative recommender systems the people collaborate to help one another to perform $ltering by recording their reactions to documents they read [19,27]. In a typical collaborative system people provide evaluation judgements or annotations on documents as inputs (feedback information), which the system then aggregates obtaining recommendations that later can be reused to assist another people in their search processes. In our multi-agent model this feedback activity is developed in the  following steps (in Fig. 2 the discontinuous lines symbolize this phase):  • Step 1: The interface agent gives the user’s identity ID (usually his/her e-mail) together with the set of documents DU = {d1U ; : : : ; duU }, u6#(Df) used by the user to the collaborative ltering agent.
• Step 2: The collaborative ltering agent asks user his/her opinion or evaluation judgements about DU , for example by means of an e-mail.
• Step 3: The Internet user communicates his/her linguistic evaluation judgements to the collaborative recommender system, rcy, y = 1; : : : ; #(DU ); rcy ∈ S.
• Step 4: The collaborative recommender system recalculates the linguistic recommendations of set of documents DU by aggregating again the opinions provided by other users together with those provided by the Internet user. This can be done using the 2-tuple aggregation operator xe given in De$nition 3. Then, given a chosen document dU y ∈ DU that receives a recommendation or evaluation judgement rcy from the Internet user, and supposing that in the collaborative recommender system there exists a set of stored linguistic recommendations {rc1; : : : ; rcM }, rci ∈ S associated with dyU for the information need category Ai, which were provided by M di>erent users in previous searches, then a new value of recommendation of dyU is obtained as  In this section we analyze the performance of our new multi-agent model. To do so, on the one hand, we compare its structure and operation with respect to the model developed in [6] and study its main advantages and drawbacks, and on the other hand, we research some aspects that can contribute to improve its performance, e.g. the critical number of content-based $ltering agents to use in the retrieval activity.

3.4.1. Comparative study As aforementioned, in this paper we propose a new multi-agent model in order to improve the retrieval activity of model de$ned in [ 6]. It is known that the more knowledge we have on user information needs the more possibilities we have to achieve our goal. Thus, we decide to incorporate two new elements in the model proposed in [6]: a new expression language to get a larger and better knowledge of user inofrmation needs and several technical elements that allow to exploit that knowledge to improve retrieval issues. These elements allow users to express their information needs by means of multi-weighted queries (each term can be weighted by two weights ) together with information need categories (in [6] users only used weighted queries by one weight to express their information needs) and incorporate several information $ltering agents in the multi-agent model to exploit that knowledge (in [6] we did not apply any information $ltering tool). Obviously, these new elements provide an additional value to the model de$ned in [6]. In what follows we analyze the main drawbacks and advantages of our proposal:  1. The structure of the new multi-agent model is more complicated. It contains two new action levels (the level of content-based $ltering agents and the level of collaborative $ltering agent) to  develop the information $ltering activity. Therefore, the design of the information Jows among agents is more complex and its implementation more diScult. However, this new structure allows to develop a more precise search on the Web.
2. The success of this model depends on the users’ collaboration. The model provides users new mechanisms to participate in the information search process but this requires their collaboration.
In the worst case, i.e. when the user does not use threshold weights, information need categories and does not collaborate in the generation of recommendations, the system obtains the same issues that the model de$ned in [6]. When users collaborate with the system in some of above aspects the success of the new system is guaranteed because it develops a more guided search.
3. The operation of this multi-agent model is also more complicated. It also presents an inofrmation retrieval phase as in [6] and a new phase that we call feedback phase. Therefore, the system carries out many more activities. However, we observe that these activities do not penalize seriously the respond time of the information search process due to the following reasons: • In a particular moment, when a user is searching information, the response time depends only on the retrieval phase. Thus, the feedback phase does not overload the response time of the information search process. We should point out that both phases are complementary with the use of system by the users, i.e., on the one hand, if users are satis$ed with issues obtained in the retrieval phase developed by the system then the possibilities of their participation in the feedback phase increase, and, on the other hand, if users participate in the feedback phase then the success of retrieval phase also increases.
• Apparently, the retrieval phase of this new model requires much more time than the retrieval phase of the model de$ned in [ 6] because it includes two new activities, the content-based $ltering activity and the collaborative $ltering activity. However, this is not the case. The $rst activity consists of recalculating the relevance degrees of retrieved documents ofr each information agent by applying a threshold matching function, which is an easy computation that does not need much time in each content-based $ltering agent. On the other hand, the activity of collaborative $ltering agent is developed in two steps. In the $rst one (Step 9.1 of the retrieval phase) the collaborative $ltering agent asks collaborative recommender systems the recommendations existing on the retrieved document associated with the information need category expressed by the user, a communication that clearly can overload the response time of the system. However, the impact of such communication can be reduced if the Step 9.1 is applied simultaneously to the processing of the user multi-weighted query. This means retrieving all documents recommended in the information need category provided by the user from collaborative recommender system. Thus, when the collaborative $ltering agent receives from task agent the relevant documents to the user query, it only has to recalculate relevance degrees using the recommendations previously retrieved. In such a way, Step 9.1 is developed quickly.
In the second step (Step 9.2 of the retrieval phase) the relevance degrees of documents are recalculated by means of the computing process of two values and this is a quick and easy computation.
• The rest of agents of the new model work similarly as in the model de$ned in [ 6], and therefore, they do not add more time to the information search process.
4. The query language of the multi-agent model provides users more expression possibilities to represent their information needs.

5. With such language and the $ltering tools this new model improves the issues of the inofrmation search process of the model proposed in [ 6] because it can develop a more precise information search process.
6. Consequently, it has more possibilities to improve users’ degree of satisafction, although, as aforementioned, it requires their participation.

3.4.2. Improving the performance of proposed multi-agent model The response time of the inofrmation search process of new model can be improved with the following small considerations:  1. As aofrementioned, if in the implementation of the model the Step 9.1 is applied simultaneously to the processing of the user multi-weighted query we get that the retrieval of recommendations does not increase the response time of system.
2. If we reduce the processing time required to carry out the activity of level of content-based $ltering agents then the response time of system can be reduced. There are two possibilities: (a) Reducing the number of content-based $ltering agents that participate in the search process.
For example, we can consider that the number of content-based $ltering agents is limited by the number of threshold matching functions, and then, to distribute all information agents among considered content-based $ltering agents.
(b) In the implementation of model we can include the activity of each content-based $ltering agent h in its respective information agent h. This means substituting the relevance computation developed in the information agents by the relevance computation developed in the content-based $ltering agents.

In this section we present an example of the activity of new multi-agent model. For this purpose, we consider a view of a single user I , as it was set out in Fig. 3. Furthermore, we use the set of seven labels (i.e., g = 6), shown in Fig. 1, to represent the linguistic information.
Suppose that user I expresses his/her information needs by the following linguistic multi-weighted query [(Agents; VH; VH ); (Web; H; M )] and the following information need category Ai =Web Mining.
With such request the user is expressing to have a stake in documents dealing with the topic Agents in a Web context at least in very high and high degrees respectively, i.e., by documents about Web Agents in a high degree, and in addition, he/she wants to analyze these documents from the perspective suggested by the topic “Web Mining. Furthermore, user prefers documents in which the topic “Agents” to be more important than Web, and this is expressed explicitly by assigning to these topics the linguistic relative importance weights VH and M , respectively. Together with this request the user gives interface agent his/her identity (e-mail).
The interface agent transfers all above information to the collaborative $ltering agent. This communicates the linguistic multi-weighted query to the task agent. The task agent gives the terms of the user query together with their respective linguistic threshold weights to the content-based $ltering agent level. Each content-based $ltering agent only passes the terms of the query to its respective information agent. The information agents search in the information source level those documents  http://activist.gpl,ibm.com/WhitePaper/ptc2.htm http://www.cs.umbc.edu/ cikm/iia/submitted/viewing/chen.html http://www.psychology.nottingham.ac.uk:80/aigr/research/agents/agents.html http://netq.rowland.org/isab/isab.html http://maple.net/gbd/salagnts.html  http://www.ncsa.uiuc.edu/SDG/IT94/Proceedings/Agents/spetka/spetka.html http://mmm.wiwi.hu-berlin.de/MMM/cebit engl.html http://foner.www.media.mit.edu/people/foner/Julia/subsection3 2 2.html http://www.cs.bham.ac.uk/ mw/agents/index.html http://www.Vy.com/html/About1.html  related to the terms of the query, and get a list with the most relevant links. For instance, each inofrmation agent h (h = 1; : : : ; 4) may retrieve a set of $ve links, Dh and their relevance Rh (see Table 1).
For example, supposing that F (d11; Agents) = 0:9 and F (d11; Web) = 0:5, then r11 is obtained as  r11 = xe[ (6 · F (d11; Agents)); (6 · F (d11; Web))] =  Each information agent h gives back to its respective content-based $ltering agent h a set of documents Dh together with its relevance Rh and its original representation with respect to the terms of query, i.e., {(F (djh; Agents); F (djh; Web)); j = 1; : : : ; 5}. Then, each content-based $ltering agent h $lters the received documents by applying the threshold semantics by means of a linguistic matching function eh to recalculate the relevance. Suppose that the content-based $ltering agents $lter documents obtain the following new linguistic relevance degrees RN h:  FFFFF(((((ddddd1211131415;;;;; −−−−− −−−−− −−−−−) ) ) ) )  then, the new linguistic relevance degrees are obtained as  where, for example, if the content-based $ltering agent 1 uses the linguistic matching function e2 and the representation of the documents of D1 is the following:  As can be observed the application of the threshold weights can change the relevance of the documents, and therefore, the ordering among the documents. For example, after to recalculate the relevance, the third more relevant document provided by the information agent 1 is considered the best one by the content-based $ltering agent 1.
In each content-based $ltering agent is also calculated the satisafction degrees of terms of query.
Consider that the obtained linguistic satisfaction degrees are the following:  [c11; c21] = [(L; 0:16); (L; 0:16)]; [c12; c22] = [(H; 0:1); (H; 0:4)];  [c13; c23] = [(M; 0:1); (M; 0:3)]; [c14; c24] = [(M; 0:4); (L; 0:2)];  where, for example, in the $rst content-based $ltering agent the $rst linguistic satisfaction degree is calculated as follows:  c11 = xe[e( (6 · 0:9); VH ); e( (6 · 0:6); VH ); e( (6 · 0:2); VH ); e( (6 · 0:9); VH );  Then, each content-based $ltering agent h sends task agent its sets (Dh, RN h, C h). In the task agent the documents in Dh are ordered with respect to new relevance RN h. Then, it calculates a global satisfaction degree of query for each content-based $ltering agent h, called .h. This degree is calculated by aggregating both the satisfaction degrees C h and the relative importance degrees provided by the user {pi2; i = 1; : : : ; m} by means of the 2-tuple linguistic weighted operator xlw. In our example, we obtain the following satisfaction degrees:  .1 = (L; 0:16); .2 = (H; 0:2125); .3 = (M; 0:175); .4 = (M; −0:05);  .2 = xlw[((H; 0:1); (VH; 0)); ((H; 0:4); (M; 0))] =  In the next step, the task agent gathers the best documents from those provided by each contentbased $ltering agent h according to its respective satisfaction degree .h. To do so, it calculates the probabilities of selection of the documents of each content-based $ltering agent h obtaining the following selection probabilities: Ps1 = 0:1728, Ps2 = 0:3371, Ps3 = 0:2541, Ps4 = 0:2360, where for example, Ps2 is obtained as  With these selection probabilities the task agent calculates the number of documents k(Dh) to select from each content-based $ltering agent h  where for example, k(D2) = round(( i4=1 #(Di)=4) · Ps2) = round(5 · 0:3371) = 2. Hence, the list of documents DV ordered by relevance RV that the collaborative $ltering agent receives from the task agent is the following:  (d1V ; r1V ) = (d21; rn21) = (d21; (H; 0)); (d2V ; r2V ) = (d22; rn22) = (d22; (H; −0:4));  (d3V ; r3V ) = (d42; rn42) = (d42; (M; 0:4)); (d4V ; r4V ) = (d13; rn13) = (d13; (M; 0));  Now, the collaborative $ltering agent $lters these documents by considering the recommendations on these documents proposed by other users. To do so, it recalculates again their relevance by including in the computation of the relevance the recommendations provided by the collaborative recommender system. Suppose that the recommendations existing on these documents in the collaborative recommender system are the following:  (Id1; H ); (Id4; M ); (Id5; M ) (Id1; VH ) (Id2; L); (Id3; VL) — (Id1; H ); (Id4; VH ); (Id5; H )  In the table we can observe that for the document d4V there not exist user’s judgements stored. And for example, the recommendation RC1Ai is obtained as  Then, using these recommendations the collaborative $ltering agent recalculates the relevance of documents DV by means of the 2-tuple weighted operator xw with the weighting vector [0.6,0.4], obtaining the following new set of relevance degrees RNV :  rNV = xw[(H; 0); (M; 0:33)] = (4 · 0:6 + 3:33 · 0:4) = (3:732) = (H; −0:268); 1  rNV = xw[(H; −0:4); (VH; 0)] = (3:6 · 0:6 + 5 · 0:4) = (4:16) = (H; 0:16); 2  rNV = xw[(M; 0:4); (L; −0:5)] = (3:4 · 0:6 + 1:5 · 0:4) = (2:64) = (M; −0:36); 3  rNV = (M; 0) = r4V (This relevance value does not change); 4  rNV = xw[(M; 0); (H; 0:33)] = (3 · 0:6 + 4:33 · 0:4) = (3:532) = (H; −0:468): 5  Hence, the list of documents DW ordered by relevance RW that the interface agent receives from the collaborative $ltering agent is the following:  (d1W ; r1W ) = (d2V ; r2NV ) = (d2V ; (H; 0:16)); (d2W ; r2W ) = (d1V ; r1NV ) = (d1V ; (H; −0:268));  (d3W ; r3W ) = (d5V ; r5NV ) = (d5V ; (H; −0:468)); (d4W ; r4W ) = (d4V ; r4NV ) = (d4V ; (M; 0));  In the last step of the algorithm, the interafce agent $lters this $nal ranked list of documents and gives to the internet user the most relevant documents (Df; Rf). For example if the $xed number  K = 3 then the system shows the following documents:  (d1f; r1f) = (d22; r1W ) = (http:==www:osf:org=ri=contracts=6:Rationale:frame:html; (H; 0:16)):  = (http:==lcs:www:media:mit:edu=people=lieber=Lieberary=Letizia=Letizia:html;  = (http:==netq:rowland:org=isab=isab:html; (H; −0:468)):  Later, the multi-agent system has to carry out the feedback activity in which the internet user is asked by his/her opinion about shown documents that he/she has used. This activity is easily done, and when user provides his/her evaluation judgements, the collaborative recommender system stores them and recalculates the recommendations for those documents using the operator xe as was done above.

We have presented a new fuzzy linguistic multi-agent model based on linguistic 2-tuple representation that incorporates in its activity the two more important information $ltering techniques: content-based $ltering and collaborative $ltering. In such a way, we improve the search processes on the Web and increase the users’ satisfaction degrees.
In the future, we want to study proposals that allow users to express better both their information needs and their evaluation judgements on documents to generate the recommendations.

This work has been partially supported by Research Projects TIC2002-03348 and TIC2002-03276.