Towards Adaptive Information Visualization: On the Influence of User Characteristics  Information visualization is a thriving area of research in the study of human/computer communication. Though the field has made substantial progress in measuring and formalizing visualization effectiveness, results and suggestions from the literature are sometimes inconclusive and conflicting [19]. We believe this may be attributed to the fact that existing visualizations are designed mostly around the target data set and associated task model, with little consideration for user differences. Both long term user characteristics (e.g., cognitive abilities and expertise) and short term factors (e.g., cognitive load and attention) have often been overlooked in the design of information visualizations, despite studies linking individual differences to visualization efficacy for search and navigation tasks [1,8], for information seeking tasks [7, 25], as well as anecdotal evidence of diverse personal visualization preferences [3].
Our long term goal is to explore the possibilities of user-centered visualizations, which understand that different users have different visualization needs and abilities, and which can adapt to these differences. However, before adaptation strategies can be effectively specified, we believe that the influence of user characteristics on visua lization effectiveness must be further studied and clarified. As a step in this direction, we present a user study designed to investigate the impact of different user characteristics on the effectiveness of two common data visualization techniques: bar graphs and radar graphs. With respect to previous work, we expand the set of user characteristics to also include verbal working memory and user expertise (in addition to the prior cognitive measures perceptual speed and visual working memory). Furthermore, we also broaden the set of dependent variables; in addition to user performance, we consider subjective measures such as visualization preference and ease of use.
In the rest of the paper, we first discuss related work, followed by a description of the study design. Next, we look at the impact of user characteristics on visualization effectiveness in terms of completion time, ease-of-use, and user preference, and then present our results. We conclude with a discussion of how our findings could be effectively used in an adaptive visualization system.

Existing work on identifying the factors that define visualization effectiveness has mostly focused on properties of the data to be visualized or the tasks to be performed, sometimes obtaining inconclusive and conflicting results (see [14] and [19], for an overview). Traditionally, extensive work has been done comparing the effectiveness of graphical data in terms of accuracy and speed across different chart types (e.g., bar, radar), yet this research typically did not take into account individual differences (see [6] and [20]). Notable exceptions were Lewandowsky and Spence [18], who explored the effect of expertise on user performance with scatter plots, discovering that high expertise improved accuracy, but decreased completion time. This was an early indication that the impact of individual user differences should be investigated further.
Only recently, more studies have looked at the role of user differences. [1, 5, 8] have focused on visual displays for information retrieval and navigation in complex information spaces. Velez et al. [22] have explored the link between five spatial abilities and proficiency in a visualization task involving the identification of a 3D object from its orthogonal projections. They found not only a large diversity in the spatial abilities of their study’s subjects, but also that these abilities are related to visualization comprehension. Even more recently, there has been a lot of interest in individual differences such as personality traits. In particular, Locus of control has been shown to impact performance across different visualizations relating to the degree to which users have internal and external control (see [15] and [25]). Other cognitive traits too have also been shown to have a strong influence on users' performance. The study by Conati and Maclaren [7] looked at two different visualizations to represent changes in a set of variables: a radar graph and a Multiscale Dimension Visualizer (MDV); a visualization that primarily uses color hue and intensity to represent change direction and magnitude [23]. They found that: (1) a user’s perceptual speed was a significant predictor of which of the two visualizations would work better for that user on a specific comparison task, and (2) both perceptual speed and visual spatial working memory were predictors of performance with each visualization for some of the study’s  tasks. The study we describe in this paper can be seen as an extension of this previous work in at least three fundamental ways. First, in this study we compare radar graphs with bar graphs, a much more common visualization than MDV. Thus, our findings may potentially have a much stronger impact on adaptive information visualization in general. Second, in addition to user performance, we include subjective measures such as visualization preference and ease-of-use as dependent variables in the study.
Third, we expand the set of user characteristics (perceptual speed and visual working memory) to include both user expertise and verbal working memory, and in doing so, we broaden the set of user features on which adaptation can be based.
The benefits of user-adaptive interaction have been shown in a variety of tasks and applications such as operation of menu-based interfaces, web search, desktop assistance, and human-learning [16]. However, these ideas have rarely been applied to data visualization, largely due to the limited understanding of which user characteristics are relevant for adaptivity in this domain. Two notable exceptions are the work by Gotz and Wen [14], and by Brusilovsky et al. [4]. Gotz and Wen [14] propose a technique to automatically detect a user’s changing goals during interaction with a multipurpose visualization, and adapt the visualization accordingly. In contrast, we focus on adapting the visualizations to other relevant user-dependent factors in addition to goals. In Brusilovsky et al. [4], they adapt the content of the visualization to the user’s domain knowledge in an educational system, but maintain a fixed visualization technique. By contrast, the research we present is intended to support adaptation that involves both selecting alternative visualizations for different users, as well as providing adaptive help with a given visualization to best accommodate each user’s needs.

The overall goal of the work described in the rest of the paper is to identify what specific user characteristics influence visualization effectiveness, and could therefore be exploited in user adaptive visualization systems. As case studies, we considered two basic visualization techniques: bar graphs and radar graphs (see Figure 1). We chose bar graphs because they are one of the most popular and effective visualization techniques. We chose radar graphs because, even though it has been argued that bar graphs are superior to radar graphs on common information seeking tasks [10], the reality is that radar graphs are still widely used. In our user study, we aim to answer the following questions: Q1: Are bar graphs better than radar graphs on common information seeking tasks? Does the answer to this question depend on specific user characteristics? Q2: Do specific user characteristics influence the effectiveness of bar graphs? Likewise for radar graphs? To answer these questions we assessed three measures of bar graph and radar graph the effectiveness (completion time, ease-of-use, and user preference), on a series of information seeking tasks. In the rest of this section, we first describe the individual characteristics we chose to investigate and then present the study tasks and design details.

The individual characteristics we investigate in this study include three cognitive abilities (perceptual speed, verbal and visual working memory), as well as two measures of user expertise, one for each of the two visualizations prior to the study.
User expertise was chosen because expertise is not only a good predictor for performance in general, but it has also been shown to impact visualization effectiveness in complex search tasks [1]. Participants self-reported their expertise by expressing their agreement with the following statement for each visualization type: "I am an expert in using radar(bar) graphs," on a Likert-scale from 1 to 5.
Perceptual speed and visual working memory were selected because they were part of the original set of cognitive measures related to perceptual abilities that were explored by Velez et al. [22]. They were also the only two in the set for which [7] found significant relationships with visualization effectiveness when comparing radar graphs and Multiscale Dimension Visualizer (MDV). Verbal working memory was selected because it may affect performance in processing the textual components of a visualization, which, in our study, include legends, labels, and task descriptions.

Thirty-five subjects (18 females) ranging in age from 19 to 35, participated in the experiment. Ten participants were CS students, while the rest came from a variety of backgrounds, including microbiology, economics, classical archaeology, and film production. Participants were asked to perform a set of tasks evaluating student performance in eight different courses. The tasks were based on a set of low-level analysis tasks that Amar et al. [2] identified as largely capturing people’s activities while employing information visualization. The tasks were chosen so that each of our two target visualizations would be suitable to support them. A first battery of tasks involved 5 questions comparing the performance of one student with the class average for 8 courses (single scenario tasks), e.g., "In how many courses is Maria below the class average?". A second battery of tasks involved 4 questions comparing the performance of two students and the class average in order to increase task complexity  (double scenario tasks), e.g., "Find the courses in which Andrea is below the class average and Diana is above it?". Arguably, the double scenario tasks are more complex since they involve more comparisons and an increase in visual clutter. Participants repeated each of the 5 tasks in the single scenario with two different datasets that varied in terms of skewness of the value distribution to account for a possible effect of distribution type on visualization effectiveness. Specifically, we compared a spiky distribution with a close-to-uniform distribution, where the spiky distribution was created by alternating student grades between high and low for some of the courses displayed in adjacent positions (Fig. 1). We did not include variations on distribution in the double scenario in order to keep the experiment’s length under one hour, as this is generally recommended for studies involving visual attention [13].

The study was divided in two phases corresponding to the task batteries for the single and double scenarios. For single scenario tasks, the experiment used a 2 x 2 x 5 (visualization type x distribution type x task) within-subject design. There were also two orders of presentation for visualization type and two orders of presentations for distribution type, which constitute two between-subject control variables introduced to account for ordering effects. For double scenario tasks, the design was a 2x4 (visualization type x task) within-subject design, with order of visualization type as a between-subject control variable. The experiment was conducted on a generic PC computer running Windows XP, with a 3.20GHZ processor, 2.00 GB RAM, and a 17 inch screen. The experimental software was fully automated and was coded in Python.

The experiment was designed and pilot-tested to fit in a single session lasting at most one hour. It was divided into three components: (1) the cognitive tests, (2) the main sequence of tasks and (3) a post-questionnaire. Participants began by completing the three tests for cognitive measures. They first performed the computer-based OSPAN test for Verbal Working Memory [21] (lasting between 7 and 12 minutes), followed by the computer-based test for Visual Working Memory [12] (10 minutes long) and finally the paper-based P-3 test for Perceptual Speed [9] (3 minutes long).
Participants were then stationed in front of the study computer for the main task portion of the experiment. Each participant performed the 14 tasks described earlier two times, once for each visualization type. The presentation order with respect to visualization type and distribution type was fully counterbalanced across subjects. Each task consisted of presenting the participant with a radar/bar graph displaying the relevant data, along with a textual question. Participants would then select their answer from a drop-down menu and click OK to advance to the next task. Upon completion of the task portion of the experiment, participants were given a post-questionnaire consisting of (1) self-reported expertise with each visualization prior to the experiment; (2) items to gauge user preference for each visualization; (3) items to assess the subjective easeof-use for each visualization.

Completion Time: Our software recorded the total amount of time in milliseconds that participants spent on each task. We use this measure as the primary metric for task performance because there is a ceiling effect on task correctness given that subjects could take as much time as they wanted to generate an answer.
Visualization Preference: Preference ratings for each of the two visualizations were collected in the post-questionnaire via the two statements "I prefer to use bar graph for answering the questions" and "I prefer to use radar graph for answering the questions", rated on a Likert scale from 1 to 5.
Ease-of-Use: A subjective assessment of overall ease-of-use of each visualization was collected in the post-questionnaire by asking participants to rate on a Likert scale from 1 to 5 the two statements: "In general, radar graph was easy to understand," and "In general, bar graph was easy to understand." We used "easy to understand" rather than "easy to use" since the visualizations in the study were not interactive, and thus it was more natural to express usability in terms of understandability.

The goal of this section is to address our study questions Q1 and Q2, by comparing the effectiveness of radar and bar graphs on the tasks described earlier and by investigating whether our selected user characteristics influence this effectiveness. In discussing the results obtained using the General Linear Model and Multivariate analysis, we report statistical significance at the 0.05 level, as well as partial eta squared (ηp²) for effect size, where .01 is a small effect, .09 is a medium effect, and .25 is a large effect [11]. We separate the analysis of completion time between single scenario and double scenario because in the single scenario phase we have an additional between-subject control for order of distribution type as discussed in section 3.2. We summarize the results of the measured user characteristics in Table 1. The rather large variances for most measures indicate that our user population was quite diverse with respect to these measures.

In order to study completion time for the tasks in the single scenario phase, we ran a repeated-measures 2 (visualization type) by 2 (distribution type) by 5 (task) general linear model with visualization-type order, and distribution-type order as betweensubject factors, and the individual characteristics as covariates. The sphericity assumption was verified for this data set using Mauchly's test. The following points summarize the findings from this analysis:   There is a large significant effect of visualization type (bar vs. radar), F(1, 20) = 8.06, p = .01 ηp²= 0. 29. Completion time was faster with bar graphs (M = 14.25s, SE = 0.6s), than with radar graph (M = 19.0s, SE = 0.76s).
 There is a large significant main effect of perceptual speed, F(1,20) = 7.61, p = .01, ηp²= 0.28, indicating that the higher the perceptual speed, the faster the completion time for both visualizations. The mean completion time for participants with low vs. high perceptual speed was 18 and 16 seconds, respectively (where high/low is defined based on the median split of perceptual speed values). This result confirms previous findings that differences in cognitive measures can impact general visualization effectiveness and, like in [7], it singles out perceptual speed as a relevant measure.
 There is a medium-large significant interaction effect between visualization type and perceptual speed, F(1,20) = 4.49, p < .05 ηp²= 0.18. Even though completion time is always faster with the bar graph, the difference in time performance between bar and radar decreases as a user's perceptual speed increases (See Figure 2left). This result is important because it confirms the finding in [7] that perceptual speed is a cognitive measure that can impact the compared effectiveness of two different visualizations, at least when one of them is a radar graph.

Fig. 2. Charts showing mean completion times for the effect of perceptual speed with graph type (left), and the interaction between visualization type and visualization order (right)   There is a large significant interaction effect between visualization type and visualization order, F(1,20) = 8.66, p < .01, ηp²= 0.30. Subjects that saw radar graphs first, proceeded to perform better with bar graphs than those who saw bar graphs first. Conversely, subjects who saw bar graphs first, proceeded to perform better on radar graphs than those who saw radar graphs first (see Figure 2-right). Thus, it appears that there is a training effect between visualizations, despite the fact that task details are changed from the first to the second visualization provided. What is likely happening is that the user is becoming familiar with the general task context/domain (e.g., the fact that the user is looking for values of school courses) after seeing it with the first visualization provided, which facilitates task performance with the second visualization.

For the double scenario, we ran a repeated-measures 2 (visualization type) by 4 (task) general linear model with visualization order as a between-subject factor, along with the individual characteristics as covariates. The only significant effect found was a medium-sized effect of task, F(2, 50) = 4.32, p < .05, ηp²= 0.14. This effect suggests that, in this phase there is a larger spread of difficulty across tasks as compared to the single scenario phase, resulting in a significant impact of the double scenario tasks on completion time. We find the lack of a significant effect of visualization type interesting (p = .465, ηp²= 0.02), because it opens the possibility to challenge claims in the literature that bar graphs are generally superior to radar graphs (e.g., [10, 20]). Given the low effect size, the lack of significant effect for visualization type may be due to a training effect generated by the participants' interactions with the two visualizations in phase one, which managed to eliminate the effect of visualization type detected in phase one. An alternative explanation is that radar graphs are as good as bar graphs for the types of comparison tasks covered in the double scenario phase. While we do not have data to reliably choose between these two explanations, the fact remains that we have encountered a scenario in which radar graphs are as effective as bar graphs, a unique finding to the best of our knowledge. There are also two marginally significant effects that we believe are worth mentioning here because their medium-large effect size indicates a potential for statistical significance given an increased experimental power. First, perceptual speed has a marginally significant main effect, F(1,26) = 3.87, p = .06, ηp²= 0.13, which reflects the influence of this cognitive measure on visualization effectiveness, similar to what was detected in the single scenario phase.
Second, radar expertise has a marginally significant main effect, F(1,26) = 4.01, p = .055, ηp²= 0.14, suggesting that for the simpler tasks in the single scenario, the training provided to participants as part of the experimental setup managed to remove differences due to existing expertise, yet for the more difficult tasks in the double scenario phase, expertise starts having an effect. Furthermore, the effect of radar expertise is in terms of overall completion time for both visualization types, which means that radar expertise is linked to both radar graph and bar graph performance.

Figure 3-left shows the distribution of preference ratings for bar and radar graph.
The distribution of ratings for the bar graph is skewed towards high values, whereas it is more uniformly distributed for the radar graph, indicating a higher variance in user preferences for the radar graph visualization. Figure 3-right shows ease-of-use ratings for bar and radar graph. More users give their highest rating to the bar graph than users who do so for the radar graph. However, it is worth noting that both the radar and bar graph are skewed towards high values, indicating that neither visualization is particularly difficult to understand.

Preference and Ease of use data was collected using a standard 5 point Likert scale, and as such is not suitable for standard parametric analysis due to the lack of normality [17]. We applied the Aligned Rank Transformation (ART) using the ART-Tool [24] to transform our Likert rating scales for Radar Preference, Bar Preference, Radar Ease-of-Use, and Bar Ease-of-Use into normalized distributions which can then be correctly analyzed using standard parametric analysis. We used a multivariate analysis with preference and ease of use ratings as the dependent variables, along with the user characteristics as covariates. The following cognitive measures were found as significant:   A large significant effect of visual working memory on radar preference, F(1, 26) = 10.65, p < .01, ηp²= 0.29. In general, users with higher visual working memory had higher preference ratings for radar graphs.
 A large significant effect of verbal working memory on bar ease-of-use, F(1, 26) = 9.69, p < .01, ηp²= 0.27. In general, users with lower verbal working memory had a higher ease-of-use rating for bar graphs.

These findings are extremely interesting, for two reasons. First, they are further evidence that user characteristics in general affect a user's experience with visualizations. Second, they indicate that different characteristics may influence different fac tors that contribute to the user’s overall experience with a visualization. In the case of our study, perceptual speed influenced actual performance (completion time), whereas visual working memory and verbal working memory influenced subjective preference and ease-of-use, respectively.
We also found significant effects for Bar Expertise and Radar Expertise1:   A very large significant effect of Radar Expertise on Radar Preference, F(1, 26) = 45.80, p < .001, η²= 0.64, as well as Radar Ease-of-Use, F(1, 26) = 19.6, p < .001, ηp²= 0.43. We found that users with higher radar expertise had a stronger preference for radar graphs.
 A very high significant effect of Bar Expertise on Radar Ease-of-Use, F(1, 26) = 931.86, p < .001, ηp²= 0.97. Users with a higher bar expertise also had a higher rated ease-of-use for radar graphs.

Whereas it is quite intuitive that expertise should influence degree of preference and perceived ease-of-use, it is interesting that, in our study, expertise influences only subjective measures, and not actual performance.

Our user study clearly shows that the user characteristics we have considered do influence the effectiveness of bar and radar graphs. The next question is: what are reasonable adaptation strategies with respect to these characteristics? We envision two possible forms of adaptation: one would select different visualizations for different users, and the other would provide only some users with additional support, which they will likely find beneficial when inspecting a given visualization.
To illustrate, let us assume that our adaptive system has a model of the current user that specifies values for her characteristics. Now, if the target visualization is intended to support simple, single-scenario-like tasks, bar charts should be the default choice.
However, if the user is low on perceptual speed, she may benefit from adaptive interventions, such as highlighting or arrow pointing to portions of the visualization relevant to the task. In contrast, if the visualization is intended to support more complex, double-scenario-like tasks the adaptation may consist of selecting a different visualization for different user groups. For instance, users with high Visual Working Memory or high Radar Graph Expertise would likely prefer a radar graph, while users with none of these features would be more effective with bar charts.

This paper presents a user study that investigates the impact of four different user characteristics on the effectiveness of two common data visualization techniques: bar  1 Computing interaction effects between ART transformed measures is non-trivial, so we leave it to future work for this set of findings.

graphs and radar graphs. The results of our study confirm and extend preliminary existing findings that individual user characteristics do make a difference in visualization effectiveness. So, we argue, these characteristics should be taken into account when selecting suitable visualization support for each particular viewer.
For the specific comparison between bar graphs and radar graphs, we found that while bar graphs are more effective (in terms of completion time) on simple information seeking tasks, the difference in performance with radar graphs is mediated by perceptual speed, decreasing for users with high perceptual speed. Furthermore, we found that the two visualizations seem to be equivalent on more complex tasks. It is an open question to verify which of the two visualizations would be more effective on a set of tasks more complex than the ones considered in this study.
In terms of impact of user characteristics on visualization effectiveness, in addition to the abovementioned interaction between perceptual speed and visualization type, we found a strong effect of perceptual speed on completion time with each visualization. We also found effects of different user characteristics (visual working memory, verbal working memory, self-reported expertise) on subjective measures of user preferences and perceived ease-or-use for each visualization.
In order to apply these results in adaptive visualization, the system must be able to acquire a model of the user characteristics. Furthermore, suitable adaptation strategies must be devised. These are the two problems we are going to work on next.
There are several other interesting ways in which this work could be extended. We plan to re-run a similar study on more complex information visualizations intended to support decision-making. Our hypothesis is twofold: first, we expect the impact of individual differences on time-based performance to be even more pronounced than what we found in this study; second, because of the complexity of the associated tasks, we expect to be able to see effects on task accuracy in addition to completion time. Finally, we will also start experimenting with adaptive visualizations based on our findings on these more complex visualizations.