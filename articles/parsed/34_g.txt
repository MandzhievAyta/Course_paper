The purpose of information extraction (IE) systems is to extract domain-specific information from natural language text. IE systems typically rely on two domain-specific resources: a dictionary of extraction patterns and a semantic lexicon. The extraction patterns may be constructed by hand or may be generated automatically using one of several techniques. Most systems that generate extraction patterns automatically use special training resources, such as texts annotated with domain-specific tags (e.g., AutoSlog (Riloff 1993; 1996a), CRYSTA(LSoderland et al. 1995), RAPIER(Califf 1998), SRV(Freitag 1998), WHISK(Soderland 1999)) or manually fined keywords, frames, or object recognizers (e.g., PALKA(Kim & Moldovan 1993) and LIEP (Huffman 1996)). AutoSlog-TS (Riloff 1996b) takes a ferent approach by using a preclassified training corpus in which texts only need to be labeled as relevant  or irrelevant to the domain. Semantic lexicons 1 for information extraction are almost always constructed by hand because general-purpose resources, such as WordNet(Miller 1990), do not contain the necessary domain-specific vocabulary. However there have been recent efforts to automate the construction of domainspecific semantic lexicons as well (Riloff & Shepherd 1997; Roark & Charniak 1998).
Weexplore the idea of learning both a dictionary of extraction patterns and a domain-specific semantic lexicon simultaneously. Furthermore, our technique requires no special training resources. The input to our algorithm is a set of unannotated training texts and a handful of "seed" words for the semantic category of interest. The heart of our approach is a mutual bootstrapping technique that learns extraction patterns from the seed words and then exploits the learned extraction patterns to identify morewords that belong to the semantic category. Wealso introduce a second level of bootstrapping that retains only the most reliable lexicon entries from the results of mutual bootstrapping and restarts the process with the enhanced semantic lexicon. This two-tiered bootstrapping process is less sensitive to noise than a single level of bootstrapping and produces highly-quality dictionaries.
In this paper, wefirst describe the mutual bootstrapping algorithm that generates both a semantic lexicon and extraction patterns simultaneously. In the second section, we describe howthe mutual bootstrapping process is itself bootstrapped to produce more accurate dictionaries at each iteration. In the third section, we present the results from experiments with two text collections: a set of corporate web pages, and a corpus of terrorism newswirearticles.

Mutual Bootstrapping Information extraction (IE) systems are designed extract specific types of information from text. The categories of interest are defined in advance and usually require the extraction of noun phrases (NPs), such as the names of people, companies, or locations. For  1For our purposes, a semantic lexicon just refers to a dictionary of wordswith semantic category labels.

someIE tasks, the set of possible extractions is finite.
For example, extracting country names from text is straightforward because it is easy to define a list of all countries. However, most IE tasks require the extraction of a potentially open-endedset of phrases. For example, it is impossible to enumerate all noun phrases that might describe a person, company, or location.
Most IE systems use both a semantic lexicon of knownphrases and a dictionary of extraction patterns to recognize relevant noun phrases. For example, an IE system to identify locations might use a semantic lexicon that lists country names and the 50 U.S. states, and then rely on extraction patterns to recognize other location phrases such as cities, neighborhoods, and general descriptions like "downtown"or "northwest region". The semantic lexicon can also support the use of semantic constraints in the extraction patterns.
Our goal is to automate the construction of both a lexicon and extraction patterns for a semantic category using bootstrapping. The heart of our approach is based on the observation that extraction patterns can generate new examples of a semantic category, which in turn can be used to identify newextraction patterns.
Wewill refer to this process as mutual bootstrapping.
The mutual bootstrapping process begins with a text corpus and a handful of predefined seed words for a semantic category. Before bootstrapping begins, the text corpus is used to generate a set of candidate extraction patterns. We used AutoSlog (Riloff 1993; 1996a) in an exhaustive fashion to generate extraction patterns for every noun phrase in the corpus. Given a noun phrase to extract, AutoSlog uses heuristics to generate a linguistic expression that represents relevant context for extracting the NP. This linguistic expression should be general enoughto extract other relevant noun phrases as well. Because we applied AutoSlog exhaustively, the complete set of extraction patterns that it produced is capable of extracting every noun phrase in the training corpus. Wethen applied the extraction patterns to the corpus and recorded their extractions.
Using this data, the mutual bootstrapping procedure identifies the extraction pattern that is most useful for extracting known category members. This extraction pattern is then used to propose new phrases that belong in the semantic lexicon. Figure 1 outlines the mutual bootstrapping algorithm. At each iteration, the algorithm saves the best extraction pattern for the category to a list (Cat_EPlist). All of its extractions are assumed to be category members and are added to the semantic lexicon (SemLex). Then the next best extraction pattern is identified, based on both the original seed words plus the new words that were just added to the lexicon, and the process repeats. Since the semantic lexicon is constantly growing, the extraction patterns need to be rescored after each iteration. An important question is howlong to run the bootstrapping loop. The simplest approach is to use a threshold cutoff, but we will discuss this issue morein the eval uation section.
The scoring heuristic is based on howmanydifferent lexicon entries a pattern extracts. This scoring metric rewards generality; a pattern that extracts a variety of category memberswill be scored higher than a pattern that extracts only one or two different category members, no matter how often. Scoring is also based on a "head phrase" matching scheme instead of requiring an exact match. Head phrase matching means that X matches Y if X is the rightmost substring of Y.
For example, "New Zealand" will match any phrase that ends with "NewZealand", such as "eastern New Zealand" or "the modern day NewZealand". It would not match "the NewZealand coast" or just "Zealand".
Head phrase matching is important for generality because any noun phrase can be preceded by an arbitrary numberof modifiers.

Generateall candidate extraction patterns fromthe training corpus using AutoSlog.

Apply the candidate extraction patterns to the training corpus and save the patterns with their extractions to EPdata  1. Score all extraction patterns in EPdata.
2. best_EP= the highest scoring extraction pattern not already in Cat_EPlist 3. Addbest_EP to Cat_EPlist 4. Addbest_EP’s extractions to SemLex.
5. Goto step 1  Each NP was stripped of leading articles, common adjectives (e.g., "his", "its", "other"), and numbers before being matched and saved to the lexicon. We used a small stopword list 2 and a number recognizer to discard overly general words such as pronouns and numbers. Using these criteria, we scored each extraction pattern using the RlogF metric used previously by AutoSlog-TS (Riloff 1996b). The score for extraction pattern i is computedas:  where Fi is the numberof unique lexicon entries among the extractions produced by patterni, Ni is the total number of unique NPs that patterni extracted, and R4 = F, This metric was designed for information extraction tasks, where it is important to identify not  2Mostinformation retrieval systems use a stopwordlist to prevent extremely commonwords from being used for retrieval purposes. Our stopwordlist contained 35 words, mainly pronouns, determiners, and quantifiers.

only the most reliable extraction patterns but also patterns that will frequently extract relevant information (even if irrelevant information will also be extracted).
For example, the pattern "kidnapped in <x>" will extract locations but it will also extract manydates (e.g., "kidnapped in January"). Even if it extracts dates and locations equally often, the fact that it frequently extracts locations makesit essential to have in the dictionary or manylocations will be missed. Intuitively, the RlogF metric tries to strike a balance between reliability and frequency. The R value is high whenthe pattern’s extractions are highly correlated with the semantic category, and the F value is high whenthe pattern extracts a large numberof category members.
Figure 2 showsthe results of the first five iterations of mutual bootstrapping to build location dictionaries from a terrorism corpus. Ten seed words were used: bolivia, city, colombia, district, guatemala, honduras, neighborhood, nicaragua, region, town. An asterisk after a noun phrase means that the noun phrase was acquired as a category memberthrough bootstrapping.
The F and N values for each pattern are shown in parentheses. Note that because of head phrase matching, "chapare region" will match the seed word "region" and be counted as a location when scoring the extraction pattern. But since that exact phrase was not in the lexicon before, it is considered to be a new location and added to it.

Best pattern Knownlocations Newlocations Best pattern Knownlocations Newlocations Best pattern Knownlocations Newlocations  "headquartered in <x>" (F=3,N=4) nicaragua san miguel, chapareregion, san miguel city "gripped <x>" (F=2,N=2) colombia, guatemala  none "downed in <x>" (F=3,N=6) nicaragua,san miguel*, city area, usulutan region, soyapango "to occupy <x>" (F=4,N=6) nicaragua, town small country, this northernarea, san sebastian neighborhood, private property "shot in <x>" (F=5,N=12) city, soyapango* jauja, central square,head, clash, back, central mountainregion, air, villa eksalvadordistrict, northwesternguatemala,left side  mistakes came from the pattern "shot in <x>", because this expression can refer to non-location phrases such as body parts. Also, most of these extraction patterns occur infrequently in the corpus. Although "headquartered in <x>" and "gripped <x>" are good location extractors, together they appeared only seven times in the 1500 training texts. As we will show in the next section, there are manyother location patterns that occur much more frequently and are therefore more important to have in the dictionary.

The mutual bootstrapping algorithm works well but its performance can deteriorate rapidly when noncategory words enter the semantic lexicon. Once an extraction pattern is chosen for the dictionary, all of its extractions are immediately added to the lexicon and a few bad entries can quickly infect the dictionary.
For example, if a pattern extracts dates as well as locations, then the dates are added to the lexicon and subsequent patterns axe rewarded for extracting them.
To makethe algorithm more robust, we introduced a second level of bootstrapping. The outer bootstrapping mechanism, which we call meta-bootstrapping, compiles the results from the inner (mutual) bootstrapping process and identifies the five mostreliable lexicon entries.
These five NPs are retained for the permanent semantic lexicon and the rest of the mutual bootstrapping process is discarded. The entire mutual bootstrapping process is then restarted from scratch. The metabootstrapping process is illustrated in Figure 3.

I~ooTsT..PP,.~ io~e,~zeI--~ ee,~ct~sLEP I --I.man,io  To determine which NPs are most "reliable", we score each NP based on the number of different category patterns (membersof Cat_EPlist) that extracted it. This criteria is based on the intuition that a noun phrase extracted by three different category patterns is more likely to belong to the category than a noun phrase extracted by only one pattern. Wealso add in a small factor to account for the strength of the patterns that extracted it. This is used mainly for tie-breaking purposes. The scoring formula is shown below, where Ni is the number of different category patterns that extracted N Pi.

WebLocation WebTitle Patterns Patterns offices in <x> served as <x> facilities in <x> became <x> operations in <x> company as <x> loans in <x> to become <x> operates in <x> experience as <x> locations in <x> q. is <x> producer in <x> appointed as <x> states of <x> to serve as <x> seminars in <x> elects <x> activities in <x> <x>capitalize consulting in <x> williams is <x> countries of <x> position of <x> rep. of <x> retired <x> outlets in <x> expectations of <x> consulting in <x> promotion to <x> customers in <x> founded as <x> diensten in <x> established as <x> distributors in <x> assistant to <x> services in <x> meyerson is <x> expanded into <x> <x> seated  Web Company Patterns owned by <x> both as <x> <x> employed <x>is distributor <x> positioning marks of <x> motivated <x> <x> trust company sold to <x> devoted to <x> <x>consolidated stmts.
<x> thrive message to <x> <x>is obligations <x> request information <x>is foundation <x>has positions incorporated as <x> offices of <x> <x>required to meet  Terrorism Location Patterns living in <x> traveled to <x> become in <x> sought in <x> presidents of <x> parts of <x> to enter <x> condemned in <x> relations between <x> ministers of <x> part in <x> taken in <x> returned to <x> process in <x> involvement in <x> intervention in <x> linked in <x> operates in <x> kidnapped in <x> refuge in <x>  Terrorism Weapon Patterns <x> exploded threw <x> bringing <x> seized <x> quantity of <x> surrender <x> search for <x> rocket <x> <x> parked hurled <x> clips for <x> defused <x> million in <x> confiscated <x> <x> was hurled placed <x> rounds for <x> consisted of <x> firing <x> explosion of <x>  k=l The main advantage of meta-bootstrapping comes from re-evaluating the extraction patterns after each mutual bootstrapping process. For example, after the first mutual bootstrapping run, five new words are added to the permanent semantic lexicon. Then mutual bootstrapping is restarted from scratch with the original seed words plus these five newwords. Now,the best pattern selected by mutual bootstrapping might be different from the best pattern selected last time.
This produces a snowball effect because its extractions are added to the temporary semantic lexicon which is the basis for choosing the next extraction pattern. In practice, what happens is that the ordering of the patterns changes (sometimes dramatically) between subsequent runs of mutual bootstrapping. In particular, more general patterns seem to float to the top as the permanent semantic lexicon grows.
Figure 4 shows the top 20 extraction patterns produced for several categories after 50 iterations of metabootstrapping. Note that the top five terrorism location patterns are different from the top five terrorism location patterns generated by mutual bootstrapping alone (shown in Figure 2). The top five patterns produced by meta-bootstrapping are much more common, extracting a total of 79 unique NPs, while the top five patterns produced by mutual bootstrapping extracted only 30 unique NPs.

To evaluate the meta-bootstrapping algorithm, performed experiments with two text collections:  corporate web pages collected for the WebKB project (Craven et al. 1998) and terrorism news articles from the MUC-4corpus (MUC-4 Proceedings 1992). For training, we used 4160 of the web pages and 1500 of the terrorism texts. Wepreprocessed the web pages first by removing html tags and adding periods to separate independent phrases. ~ AutoSlog generated 19,690 candidate extraction patterns from the web page training set, and 14,064 candidate extraction patterns from the terrorism training set. 4 Then we ran the meta-bootstrapping algorithm on three semantic categories for the web pages (locations, person titles, and companies), and two semantic categories for the terrorism articles (locations and weapons). Weused the seed wordlists shownin Figure 5. Weused different location seeds for the two text collections because the terrorism articles were mainly from Latin America while the web pages were much more international.
Weran the meta-bootstrapping algorithm (outer bootstrapping) for 50 iterations. The extraction patterns produced by the last iteration were the output of the system, along with the permanent semantic lexicon. For each meta-bootstrapping iteration, we ran the mutual bootstrapping procedure (inner bootstrapping) until it produced 10 patterns that extracted at least one new NP(i.e., not currently in the semantic  3Webpages pose a problem for NLPsystems because separate lines do not always end with a period (e.g., list items and headers). Weused several heuristics to insert periods wheneveran independent line or phrase was suspected.
4AutoSlog actually generated manymore extraction patterns, but for practical reasons we only used the patterns that appeared with frequency > 2.

Web Company Web Location Web Title Terr. Location Terr. Weapon  lexicon). But there were two exceptions: (1) if best pattern had score < 0.7 then mutual bootstrapping stopped, or (2) if the best pattern had score > 1.8 then mutual bootstrapping continued. Intuitively, mutual bootstrapping stops when the best pattern looks especially dubious (its extractions would be risky to add to the lexicon) or keeps going if it is still generating strong extraction patterns. This scheme allows mutual bootstrapping to produce a variable number of extraction patterns, depending on howreliable it believes them to be. These criteria worked well empirically on the categories that wetested, but a more formal strategy is a worthwhile avenue for future research.
First, we evaluated the semantic lexicons in isolation by manually inspecting each word. Wejudged a word to belong to the category if it was a specific category member(e.g., "IBM"is a specific company) or a general referent for the category (e.g., "the company" is a referent for companies). Although referents are meaninglessin isolation, they are useful for information extraction tasks because a coreference resolver should be able to find their antecedent. The referents were also very useful during bootstrapping because a pattern that extracts "the company"will probably also extract specific companynames.
Table 1 shows the accuracy of the semantic lexicon after the 1st iteration of meta-bootstrapping and after each 10th iteration. Each cell shows the number of true category membersamongthe entries generated thus far. For example, 32 phrases were added to company semantic lexicon after the tenth iteration and 25 of those (78%) were true company phrases. Table shows that our algorithm found about 100-200 new phrases for all of the categories, and the density of  good phrases was high. To put our results in perspective, other researchers have generated a semantic lexicon for the terrorism weaponcategory and achieved accuracy rates of 34/200 (17%) (Riloff & Shepherd 1997) and 93/257 (36%) (Roark & Charniak 1998). So results are significantly better than those reported previously for this category. To our knowledge, no one has reported results for the other categories that we tested.
Wealso wanted to verify that the phrases in the semantic lexicon would be likely to appear in new texts.
So we created a test set by manually tagging all noun phrases that were legitimate extractions for each category in 233 new web pages. 5 Table 2 shows the recall and precision scores on the test set for three experiments. In the first experiment (Baseline), we generated a baseline by extracting all noun phrases in the test set that contained one of the original seed words.
In the second experiment (Lexicon), we manually filtered the semantic lexicon to remove incorrect entries and then extracted every noun phrase in the test set that contained a lexicon entry. In the third experiment (Union), we extracted all noun phrases in the test set that either contained a lexicon entry or were extracted by an extraction pattern generated for the category.

Recall/Precision (~o) Web Company Web Location Web Title  locations and titles in corporate webpages, so we probably need to generate a muchlarger lexicon of company namesto achieve good results for this category.
The third column (Union) shows that using the lexicon and the extraction patterns to identify newinformation slightly increases recall for locations and titles, but also slightly decreased precision. In retrospect, we realized that we probably need to use more extraction patterns. For this experiment, we only used patterns with a score > 0.7, which produced only 63 title extraction patterns and 87 companyextraction patterns.
Since the patterns represent very specific linguistic expressions, we probably need to lower that threshold.
Wealso plan to consider schemesfor allowing both the semantic lexicon and the extraction patterns to vote on possible extractions.

Bootstrapping is a powerful technique for leveraging small amounts of knowledge to acquire more domain knowledge automatically. An important aspect of our bootstrapping mechanismis that it generates domainspecific dictionaries. For example, the location dictionary generated from the web pages contained mainly country names and U.S. cities while the location dictionary generated from the terrorism articles contained mostly cities and towns in Latin America. Generating domain-specific dictionaries is a strength because the dictionaries are tailored for the domainof interest. But some categories maybehave strangely if one does not anticipate their role in the domain. For example, we tried using this bootstrapping technique for the semantic category "vehicle" using the terrorism corpus, but the resulting dictionaries looked remarkably similar to the weapondictionaries. In retrospect, we realized that vehicles are often weaponsin the terrorism texts, either as car bombsor fighter planes. So in this domain, considering vehicles to be weaponsusually makessense.
In summary, we have shown that multi-level bootstrapping can produce high-quality dictionaries for a variety of categories. Our bootstrapping method has two advantages over previous techniques for learning information extraction dictionaries: both a semantic lexicon and a dictionary of extraction patterns are acquired simultaneously, and no special training resources are needed. Our algorithm needs only a corpus of (unannotated) training texts and a small set seed words as input. The resulting semantic lexicon does need to be manually inspected to get rid of bad entries, but this can be done in a few minutes. Multilevel bootstrapping appears to be a promising approach for acquiring domain knowledge automatically, and we hope to apply this technique to other knowledgeacquisition tasks as well.

This research is supported in part by the National Science Foundation under grants IRI-9509820, IRI-