In biological systems, spatial and temporal information is captured and mapped into motor actions by neuronal networks with evolved architectures and time-dependent dynamics. In man-made systems, there are two major classes of artificial neuronal networks that can capture spatial and temporal information: Continuous Time Recurrent Neural Networks (CTRNN) [2] and Spiking Neural Networks (SNN) [3].

Some scientists have been trying to unveil the mechanisms of vision-guided behaviour by combining behavioural and neuro-physiological analysis with modelling and development on vision-guided mobile robots. Some of the major actors in this field include the teams led by Franceschini [4] at CNRS in Marseilles, by Buelthoff [5] at Max-Planck Institute in Tuebingen, and by Srinivasan [6] at the Australian National University in Canberra. Some of these models can be formalized in terms of CTRNN or as collections of non-linear filters.
However, these methods require relatively high memory storage and computation power to handle time constants, synaptic weights, or other parameters and functions.

Spiking neurons have been mainly studied and formalized within the biology-oriented community. In this project, we decided to investigate spiking neurons as candidates for our micro-systems because they communicate by binary events that can be easily mapped into digital micro-controllers. Furthermore, simple leakage and refractoriness in a spiking neuron can provide rich non-linear and time-dependent dynamics. Designing functional spiking networks is still a major challenge and there are not yet many learning algorithms that can be used to find a suitable set of synaptic connections for a desired behaviour. Therefore, in this project we use artificial evolution to discover minimal networks of spiking neurons coupled to vision sensor and actuators.

The first stage of the project consisted in assessing the feasibility of evolving networks of spiking neurons for vision-guided robots [7]. To keep things simple, we started our experiments on the miniature mobile robot Khepera equipped with a linear camera.

The robot was required to navigate as straight and fast as possible for 40 seconds in a rectangular arena with randomly spaced stripes on the walls (if the stripes are regularly spaced, it is relatively trivial to detect distance from walls). A fully recurrent network of 10  spiking neurons connected to the photoreceptors of the robot was genetically encoded and evolved on the physical robot. In particular, this experiment was aimed at studying whether functional behaviours can be achieved by simply evolving the connectivity among neurons, but not their synaptic weights (in other words, all existing connections are set to strength 1, with possible inhibitory neurons). Such a network and its genetic encoding require very small memory resources and computational power. The results showed that artificial evolution could reliably generate in about 20 generations robots that navigate without hitting walls.

The second stage of the project consisted in developing a low-level implementation of the evolutionary spiking network in a PIC™ micro-controller with few bytes of memory and a few MHz of clock speed. These micro-controllers are a suitable solution for micro-flyers because they require very little power, are extremely small and light, and include most of the circuitry required to interface sensors and actuators.

The implementation of a spiking neural network with 8 neurons and 8 input units, of its genetic encoding and fitness computation, and of a steady-state evolutionary algorithm took less than 35 bytes of memory storage, approximately 500 lines of assembly-code, and an update rate of 1ms, which is comparable to the update speed of biological neural networks.
This was achieved by mapping neural dynamics and genetic operators directly into the architecture and functioning of the digital micro-controller without wasting even a single bit.
The system was then evaluated on the Alice micro-robot, which is equipped with the same family of PIC micro-controllers, to evolve a navigation and obstacle-avoidance behaviour using the same fitness function described in [8]. It took less than 20 minutes for the robot to develop and retain smooth navigation abilities in a simple maze [9]. However, in these experiments we used active infrared sensors, instead of vision, because the vision module was not yet available for the Alice micro-robot.

The third stage of the project consisted in evaluating the evolutionary spiking network for its ability to drive a vision-based blimp in a 5 by 5 meters room. In these experiments, we used the same algorithm developed in stage one for the Khepera experiments described above. The development of the autonomous indoor blimp took significant effort in order to provide it with the technology necessary to carry out evolutionary experiments.

Our blimp is equipped with two propellers for horizontal displacement, one propeller for vertical displacement, one active infrared sensor to detect altitude, a linear vision system facing forward, 6 antenna-like bumpers (not used in these experiments), a micro-controller, a BluetoothTM chip for communication with a desktop computer, rechargeable batteries, and one anemometer to estimate forward speed. At this stage, the entire algorithm runs on the desktop PC, which exchanges vision data and motor commands with the blimp every 100 ms.
The evolutionary blimp is asked to move forward as fast as possible for 60 seconds using only visual information (altitude control is provided by an automatic on-board routine). The fitness is proportional to the reading of the anemometer, which is mounted on the front of the robot.
A preliminary set of experiments indicated that artificial evolution can generate in about 20 generations spiking controllers that drive the blimp around the room [10].

A number of experiments remain to be done with the blimp. These include an experiment where altitude control is left to the evolutionary spiking network and one using the microcontroller implementation that was tested on the Alice micro-robot. These and other experiments are under way at the moment of writing.

The fourth stage of the project, currently in progress, is the development of a micro airplane capable of indoor flight. A major requirement of such an airplane is to be slow enough to  allow on-board and on-line vision acquisition, network update, and motor control using simple micro-controllers that require little power. Various prototypes have been developed and tested in wind tunnel [11]. The current prototype, shown in figure 4, weighs 45 grams, has an autonomy of 15 minutes when tele-operated, can fly within a room at walking speed, and is equipped with batteries, micro-controller, and a BluetoothTM chip. Although this may not yet be the final model, it already has a payload of 10 grams, which is sufficient for a vision system and related microelectronics.

The methodology used to evolve the spiking circuits for the Khepera, Alice, and blimp robots is not applicable to the indoor micro airplane because of its inability to recover from collisions with obstacles. The solution that we currently envisage is to evolve the control circuit in simulation and transfer the evolved individuals on the real airplane.

Of course, a straightforward transfer is not going to work because the difference between a simulated and a physical flyer is likely to be quite large. Therefore, instead of evolving the connectivity of the circuit, we will genetically encode and evolve the plasticity rules and let the spiking circuit develop suitable connection strengths literally on the fly. In previous work, we showed that this method generates circuits that adapt very quickly to the environment where they are located [12]. We also showed that such evolved systems transfer very well from simulated to physical robots (and even across different robotic platforms).

Our previous work on evolution of plasticity rules was done with conventional neural networks. In that case, the chromosomes encoded four types of plasticity rules, each being a complementary variation of the Hebb rule. These rules will have to be mapped into the temporal domain by taking into account the time difference between pre-synaptic and postsynaptic spikes. Current work on evolution of plasticity rules for spiking neurons, performed within another project aimed at creating an evolutionary and self-organizing electronic tissue [13], will help us to explore the best way of implementing such plastic circuits on microcontrollers.

Acknowledgements. The authors acknowledge important contributions by Jean-Daniel Nicoud, Cyril Halter, Michael Bonani and Tancredi Merenda for the design of the blimp and micro airplane, and Matthijs van Leeuwen for experiments with the blimp. This work is supported by the Swiss National Science Foundation, grant nr. 620-58049.

[6] K. Weber, S. Venkatesh, M. Srinivasan, Insect Inspired Behaviours for the Autonomous Control of Mobile Robots. From Living Eyes to Seeing Machines, 1997.
[7] D. Floreano, and C. Mattiussi, Evolution of Spiking Neural Controllers for Autonomous Vision-based Robots. In T. Gomi (Ed.), Evolutionary Robotics IV, Berlin: Springer, 2001.
[8] D. Floreano, and F. Mondada, Automatic Creation of an Autonomous Agent: Genetic Evolution of a Neural Network Driven Robot. In D. Cliff, P. Husbands, J.-A. Meyer, and S. Wilson (Eds.), From Animals to Animats 3. Proceedings of the Third International Conference on Simulation of Adaptive Behavior, Cambridge, MA: MIT Press, 1994.
[9] D. Floreano, N. Schoeni, G. Caprari, and J. Blynel, Evolutionary Bits’n’Spikes, To be published in Proceedings of Artificial Life (ALIFE’02), MIT Press, 2002.
[10] J-C. Zufferey, D. Floreano, M. van Leeuwen, and T. Merenda, Evolving Vision-based Flying Robots.
In Bülthoff, Lee, Poggio, Wallraven (Eds.), Proceedings of the 2nd International Workshop on Biologically Motivated Computer Vision (BMCV), Berlin, Springer, 2002.
[11] J-D. Nicoud, and J-C. Zufferey, Toward Indoor Flying Robots, Proceedings of the International Conference on Intelligent Robots (IROS’02), 2002.
[12] J. Urzelai, and D. Floreano, Evolution of Adaptive Synapses: Robots with Fast Adaptive Behavior in New Environments. Evolutionary Computation, 9, 495-524, 2001.
[13] D. Roggen, D. Floreano, and C. Mattiussi, A Morphogenetic Evolutionary System: Phylogenesis of the POEtic Tissue. Accepted for publication in: Proceedings of the Fifth International Conference on Evolvable Systems (ICES), 2003.