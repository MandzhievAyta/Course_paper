We describe evolution of spiking neural architectures to control navigation of autonomous mobile robots. Experimental results with simple ¯tness functions indicate that evolution can rapidly generate spiking circuits capable of navigating in textured environments with simple genetic representations that encode only the presence or absence of synaptic connections. Building on those results, we then describe a low-level implementation of evolutionary spiking circuits in tiny micro-controllers that capitalizes on compact genetic encoding and digital aspects of spiking neurons. The implementation is validated on a sugar-cube robot capable of developing functional spiking circuits for collision-free navigation.

I. Spiking Neural Circuits The great majority of biological neurons communicate using self-propagating electrical pulses called spikes. Computational approaches to the study of brain function de¯ne two classes of neuron models that, among other things, di®er in their interpretation of the role of spikes. Connectionist models [23], by far the most widespread, assume that what matters in the communication is the ¯ring rate of a neuron, that is, the average quantity of spikes emitted by the neuron within a relatively long time window (for example, over 100 ms). In these models the real-value output of a neuron represents the ¯ring rate, possibly normalized relatively to the maximum attainable value. Pulsed models [19], instead, are based on assumption that the ¯ring time, that is, the precise time of emission of a single spike, may convey important information [25]. Often, these pulsed network models use complex activation functions that represent the emission of spikes on a very ¯ne timescale [22].
Leaving aside the question of whether information transmitted among neurons is encoded by ¯ring rate, ¯ring time, or a combination of both, arti¯cial spiking neural networks are attracting increased attention because they could capture and exploit more e±ciently (i.e., with fewer neurons or with higher probability) non-linear time series of input signals; can be implemented in tiny and low-power chips [13] that exploit the sub-threshold physics of transistors in analog VLSI [20]; and allow biologically plausible investigations of computation in nervous systems. In this paper we are concerned mainly with the latter issue and show that adaptive networks of spiking neurons can be e±ciently implemented also in tiny, low-cost, and largely available digital circuits.

Designing circuits of spiking neurons that display a desired functionality is still a challenging task. The most successful results in the ¯eld of robotics obtained so far focused on the ¯rst stages of sensory processing and on relatively simple motor control. For example, Indiveri et al. [12] developed neuromorphic vision circuits that emulate interconnections among neurons in the early layers of the biological retina in order to extract motion information and implement a simple form of attentive selection. These vision circuits have been interfaced with a Koala robot and their output has been used to drive the wheels of the robot in order to follow lines [14]. In another line of work, Lewis et al. developed an analog VLSI circuit with four spiking neurons capable of controlling a robotic leg and adapting the motor commands using sensory feedback [18]. This neuromorphic circuit consumes less than 1 microwatt and takes less than 0.4 square millimeters of chip area.
Despite these promising implementations, there are not yet methods for developing complex spiking circuits that could display minimally-cognitive functions or learn behavioral abilities through autonomous interaction with a physical environment. Arti¯cial evolution thus may represent a promising methodology to generate networks of spiking circuits with desired functionalities expressed as behavioral criteria (¯tness function). In previous work [4], we showed that evolution of spiking circuits can generate functional networks of spiking circuits for vision-based navigation of autonomous robots. Neuro-ethological analysis of an evolved circuit revealed functional specialization of single neurons and the role of spiking correlation on behavior. More recently, DiPaolo [3] used a similar approach to investigate the role of noise and synaptic plasticity in light-directed tasks.
In this article, we expand our previous work [7], [4] and describe a compact digital implementation of evolutionary spiking circuits that capitalize on our ¯ndings that such circuits do not require speci¯cation of synaptic weights and thus result in compact genetic encodings. The resulting evolutionary spiking circuit on chip, which occupies less than 50 bytes of memory, is validated on a sugar-cube robot that autonomously and reliably develops the ability to navigate around a maze in a less than an hour. A preliminary implementation of this model was described in [7]. Here we describe a ¯nal implementation, a new set of experiments, and the analysis of evolved network architectures.
In the next section we describe the network architecture and genetic representation used  in these experiments. In the section that follows we brie°y describe a set of evolutionary experiments on vision-based navigation with a neuron model that captures non-linear dynamics of synaptic integration and post-spike membrane behavior. These experiments are based on the speci¯cations that we presented in [4]. We then describe the implementation in a micro-controller of a simpli¯ed neuron model and evolutionary algorithm and present a set of evolutionary experiments with a fully autonomous sugar-cube robot. Finally, we discuss the relationship between our low-level digital implementation and other analog VLSI implementations of spiking networks, as well as scalability issues and extensions of our model.

II. Network Architecture and Genetic Representation  In this section we describe the architecture and genetic representation of evolutionary spiking neurons, which is common to all experiments presented in this article.
The number of neurons and sensors is prede¯ned and cannot be changed by the evolutionary process. Only the connectivity pattern and neuron signs are genetically encoded and evolved. A network is composed of n neurons and s sensory neurons (¯gure 1).
Each neuron can receive connections from all neurons (including itself) and from all sensory receptors. A neuron can be excitatory or inhibitory and all outgoing connections have the same sign. Synaptic connections have weight w = 1 and their signs are determined by the pre-synaptic neuron (positive if the neuron is excitatory, negative if the neuron is inhibitory). The state of a neuron is described by its membrane potential. Incoming spikes a®ect the membrane potential; we will assume that excitatory spikes increase its value and inhibitory spikes decrease it. In the absence of input activity the membrane potential tends towards a resting value (this process is also known as leakage). When the membrane potential exceeds its ¯ring threshold, the neuron emits a spike. Following a spike, the membrane potential is lowered to a negative value from which it gradually returns to its resting potential. This hinders the emission of a new spike within the time interval that immediately follows the ¯ring event. This time interval is also known as refractory period.
Sensory neurons are not connected among themselves and are always excitatory. At each time interval, they emit a spike with a probability proportional to the response of  the corresponding sensor. The response of a sensor is linearly scaled in the interval [0; 1].
A binary genetic string encodes the sign of each neuron and the presence of synaptic connections. All other neuronal and synaptic parameters are prede¯ned and equal for all neurons. The genetic string is composed of n blocks, one for each neuron in the network.
The ¯rst bit of the block encodes the sign of the neuron and the remaining n + s bits encode the presence/absence of a connection from the n neurons and from the s sensory neurons in the network. Therefore, the total genetic length is n(1 + n + s) bits.

In this ¯rst set of experiments we assess the evolvability of connectivity patterns (presence/absence of a connection) and neuron signs of fully recurrent spiking networks for a vision-based navigation task (preliminary results and additional experimental conditions are described in [4]).

A Khepera robot equipped with a linear camera is asked to navigate in a square arena measuring 60 by 60 cm with textured walls (¯gure 2). The walls are ¯lled with black and white vertical stripes. Width and spacing of the stripes have a uniform random distribution within the interval [0:5; 5] cm.
The vision system (¯gure 3) is composed of a linear array of 64 photoreceptors (left hole) spanning a visual ¯eld of 36 deg and of a light sensor (right hole) used to adjust the sensitivity of the receptors to the global illumination level. Each photoreceptor returns a value between 0 (black) and 255 (white). Given the relatively low spatial frequency of the stripes on the walls, we read the activations of only 16 photoreceptors equally spaced on the array (1 every 4). These values are convolved with a Laplace ¯lter spanning three adjacent (sampled) photoreceptors (weights of the Laplace ¯lter are f¡:5; 1; ¡:5g) in order to detect contrast (¯gure 3). Finally, the convolved image is recti¯ed by taking the absolute values and scaling them in the range [0; 1]. The resulting 16 values represent the probabilities of emitting a spike for each corresponding sensory neuron at every update of the network.
The states of all neurons in the network (including sensory neurons) are synchronously updated every millisecond, but the sensors and motors of the robot are updated only once  every 100 ms. During this interval, the spiking probability of sensory neurons corresponds to the most recent value returned by the robot. In addition to the 16 visual neurons, there is a bias neuron that is always active and can be used by evolution to determine a basic level of activity in the network in the absence of input-generated activity.
The network consists of 10 neurons that can be connected to each other and to all sensory neurons (¯gure 1). The number of spikes emitted by four motor neurons within the last 20 ms of the sensory-motor interval (100 ms) is used to set the speeds of the two wheels in push-pull mode. Each wheel of the robot is coupled to two neurons. The ¯ring rate (number of spikes ¯red within 20 ms divided by maximum number of spikes) of one neuron is mapped into forward speed and the ¯ring rate of the other neuron is mapped into backward speed. The sum of these two direction-speci¯c speeds gives the ¯nal direction of rotation and speed of the wheel. Each wheel can take a maximum rotational speed of 80 mm/s, which would be obtained for a ¯ring rate corresponding to the production of a spike at each update cycle of the network. However, since a neuron can ¯re at maximum  once every two update cycles (because of the refractory period), the maximum speed is 40 mm/s.
In this set of experiments, we chose the Spike Response Model [8] of spiking neurons because the model is relatively simple and encompasses a large class of spiking neurons, including the simpli¯ed model that will be described later for the micro-controller implementation. In what follows, we describe the model and give between brackets the parameter values used in this experiment. In the Spike Response Model, the membrane potential Ài(t) of a neuron i at time t is obtained by adding two kernels - one, ²(s), describing the e®ect of incoming spikes, and one, ´(s), describing the refractory period - as follows  Ài(t) = X wj X ²j(sj) + X ´i(si) (1) j f f where sn = t ¡ tfn is the di®erence between current time t and the ¯ring time tf of neuron n, and wj (1 for all synapses) is the synaptic strength of the connection from neuron j.
If the membrane potential Ài(t) exceeds the neuron threshold µi (0.1 for all neurons), the neuron emits a spike and the corresponding time instant is added to the set of ¯ring times.
In these experiments The properties of the kernel ²(s) are speci¯ed by a) the delay ¢ (2 ms for all synapses) between the generation of a spike at the pre-synaptic neuron and the time of arrival at the synapse, b) a synaptic time constant ¿s (10 ms for all synapses), and c) a membrane time constant ¿m (4 ms for all synapses). A possible function ²(s) describing this behavior [9] is given by  for ¢ · s · 20, otherwise ²(s) = 0.
The refractory period depends only on the membrane time constant ¿m. A possible kernel ´(s) [9] is given by  The value returned by ´(s) is weighted by a random value with uniform distribution in the range [0; 1] in order to break ties in a network of interconnected neurons and prevent spontaneous emergence of locked oscillations.

In this set of experiments we use a generational, ¯xed population size, genetic algorithm [10]. A population of 60 individuals is evolved using rank-based truncated selection (15 best individuals, each generating 4 o®spring), one-point crossover (p = 0:1 per pair), bit mutation (p = 0:05 per bit), and elitism (size=1).
Each individual of the population is decoded and tested on the robot two times for 40 seconds each (400 sensory-motor steps). The robot is not repositioned between trials of the same individual or between di®erent individuals. The ¯tness function © is the sum of the speeds of the two wheels vleft and vright measured by the optical encoders at every time step t (100 ms), only if both wheels rotate in the forward direction, averaged over T time steps available (here T = 400 + 400)  © = 1 XT(vlteft + vrtight) (4) T t If vleft or vright are less than 0 (backward rotation) or equal to 0 (no rotation), ©t = 0. This ¯tness function selects individuals for the ability to go as straight and as fast as possible.
In addition, since the robot takes only a few seconds to travel across the arena and wheels rotate considerably less if the robot is stuck against a wall, the ¯tness function implicitly encourages selective reproduction of individuals that can avoid walls. The ¯tness function does not use the active infrared sensors available on the robot to measure distance from the walls (as we did in previous experimental work [6, e.g.]) because the response pro¯le of these sensors varies depending on the re°ection properties of the walls (black stripes re°ect approximately 40% less infrared light than white stripes) and on the infrared spectrum component of ambient illumination.
In this set of experiments, the neural network, evolutionary algorithm, and ¯tness computation are implemented on a desktop PC connected to the robot through the serial port and rotating contacts, which provide also energy supply. For a description of the methodology, see [21, chapter 3].
We have run three experiments on the physical robot. Each experiment starts with a di®erent random initialization of the genetic strings. One generation on the physical robot took 80 minutes. In all runs, arti¯cial evolution took less than 30 generations to discover spiking controllers capable of navigating around the environment and avoiding the walls. The graph on the left of ¯gure 4 displays population mean and population best  ¯tness values averaged across three runs. Fitness values above 0.6 already correspond to robots that can move forward and avoid walls. Further ¯tness gains correspond to faster and smoother trajectories (an example is shown on the right side of ¯gure 4). Fitness values of 1.0 cannot be reached because the robot sometimes must reduce the speed of one wheel in order to turn and avoid walls.
Since initial populations are randomly created, only 50% of the connections are present.
This percentage did not change signi¯cantly along generations in any of the evolutionary runs. In [4] we described several methods of analysis and used them to understand an evolved spiking controller (evolved in a di®erent arena from that used for the experiments described here). For the purpose of this paper, the most important result is that a compact genetic representation that describes only the pattern of connectivity and neuron sign is su±cient to evolve functional networks of spiking controllers. In the rest of this paper, we capitalize on this result to implement a simpli¯ed evolutionary spiking network in low-power microcontrollers.

IV. Evolutionary Spiking Circuits in a Microcontroller  A microcontroller is an integrated circuit composed of a microprocessor unit, memory, and input/output peripheral devices (¯gure 5). In other words, it is a full computer in a single chip capable of receiving, storing, processing, and transmitting signals to the external world. Most applications using microcontrollers require very low power consumption, small size, robustness to hard operating conditions, and low price. These features come at the expense of the number of transistors and instructions per second, resulting in very low computing power compared to personal computers. Consequently, low-level languages, such as assembler, are often used to exploit e±ciently every single bit of memory.
The core idea explored in this paper is that spiking circuits can be mapped quite easily into microcontrollers because spikes are essentially binary events and the non-linear dynamics and neural information is given by spiking time and spike count, rather than by non-linear, real-valued, activation functions used in connectionist neuron models. In this implementation we use a few logic operations (such as AND, NOT, and bit shift) to  implement a network of spiking neurons.
The experiments described in the previous section showed that arti¯cial evolution can easily discover functional spiking circuits by exploring only the space of neuron sign and connectivity. Both variables can be described by a single bit (1 = positive sign for neurons, connection enabled for synapses; 0 = negative sign, connection disabled for synapses) and therefore can be e±ciently stored and easily manipulated in microcontrollers.
The next two subsections will describe the neuron and evolutionary model, respectively.
Implementation details are described in Appendix A and B. The section that follows will describe an example of this implementation where a microrobot equipped with a microcontroller evolves without human intervention in less than two hours the ability to move around a maze.
The chip used in the experiments described here belongs to the PIC (Peripheral Interface Controller) family of microcontrollers by Arizona Microchip Technology (www.microchip.com).
However, the same implementation method is applicable to any other type of microcontroller.

The neuron model used in the experiments with the Khepera robot described above is much too complex to be implemented in a microcontroller because it uses several non-linear functions, requires °oating-point representation and relatively high computing speed. Therefore, the neuron model used here is a simple integrate-and-¯re model with leakage and refractory period.
The behavior of a neuron (¯gure 6) is described by the following series of steps: 1. Refractory period. If the neuron has emitted a spike within the previous time interval ¢t, the membrane potential is not updated. In these experiments, ¢t = 1.
2. The contribution of incoming spikes eit is given by the sum of spikes otj at time t through existing connections wij weighted by the sign of emitting neurons sj:  where here the threshold Àimax = 5 8i and rt is a random integer in the range [¡2; 2] to prevent the emergence of locked oscillations in networks with feedback connections.
5. Leakage. A leaking constant ki is subtracted from the membrane potential only if the result of this operation is larger or equal to the resting potential Àimin 8 t Àit = :><> Àit À¡imkini :: oÀtih¡erkwi i¸se Àimin (8)  The circuit architecture is similar to that used for the experiments on vision-based navigation described above. Each neuron can be connected to all neurons (including itself) and to all sensory neurons, as in ¯gure 1. The sign of the neuron determines the e®ect of its spikes on other neurons (equation 6). The presence of a spike in the sensory neuron is determined by the activity of sensors, as explained later.
The implementation (¯gure 7) exploits the 8-bit architecture of the microcontroller used in these experiments. Therefore, the network is composed of 8 neurons and 8 sensory neurons.
At every network cycle, the spiking state of all neurons and sensory neurons are encoded by the byte OUTPS and INPS, respectively (a bit takes value 1 if the corresponding neuron emitted a spike at the previous cycle, otherwise is 0). The sign of all neurons is described by the byte SIGN (bit value is 1 if the corresponding neuron is excitatory, 0 if it is inhibitory). The pattern of incoming connections for one neuron is described by byte NCONN for connections from neurons and by byte ICONN for connections from sensory neurons. Each neuron has one byte MEMB to store its membrane potential. The threshold of all neurons is encoded by the byte THRES. This network requires 28 bytes of RAM memory (INPS, OUTPS, SIGN, THRES, 8 x MEMB, 8 x NCONN, 8 x ICONN). Nine additional bytes are used to store random numbers, counters, and temporary variables that are shared with the evolutionary algorithm described in the next subsection.
The update of a neuron is partly done in parallel by performing AND operations between the byte storing the spikes and the byte storing the connections from excitatory neurons.
The resulting number of active bits are used to increment the membrane potential of the neuron. Contributions from inhibitory neurons are computed in a similar fashion after  taking the complement (NOT) of the byte storing the sign of all neurons and combining it with the pattern of connections. The resulting number of active bits is used to decrement the membrane potential. Network architectures of less than 8 neurons and/or sensory neurons can easily be implemented by masking (with AND) unused bits with a byte with bit value 1 for every used neuron. Details of the implementation are given in Appendix A.

The same genetic encoding used for the experiments with the Khepera (see ¯gure 1) has been used for the neuron model used here. Consequently, the genetic string of the spiking circuit consists of only 17 bytes: 1 byte for the sign of the neurons (SIGN), 8 bytes for its neural connections (NCONN), and 8 bytes for its sensory connections (ICONN). An additional byte is used to store the ¯tness of the individual.
The memory constraints of microcontrollers puts a severe limit on the number of genetic strings (individuals) maintained in the population. Therefore, a form of steady-state genetic algorithm, which experimentally showed to be suitable for small populations [26], [24], has been chosen. The algorithm used here, designed to maximize exploration while preserving the best solution obtained so far, works as follows: 1. Randomly generate a population of genetic strings and initialize their ¯tness values to zero.
2. Pick an individual at random from the population, mutate it, and measure its ¯tness.
3. If its ¯tness is equal or larger to the ¯tness of the worst individual in the population, write its genetic string and ¯tness value at the memory location of the worst individual, otherwise throw it away.
4. Go to step 2.
Mutated individuals are put back in the population even if they have the same ¯tness of the worst individual in order to allow for \neutral walks" [17] on the genetic landscape. This may be a useful property for evolution of small converged populations [11]. Implementation details of this evolutionary algorithm in the microcontroller are given in Appendix B.

The method described above has been tested on a simple evolutionary task for an autonomous micro-robot equipped with a PIC microcontroller. Alice (¯gure 8) is one of the smallest autonomous mobile robots in the world [1] with an energetic autonomy of 10 hours. Alice is a programmable and modular robot. It measures approx. 2 cm on each side and has a weight of 10 g. In its basic con¯guration it has 2 bi-directional Swatch motors that allow a maximum speed of 40 mm/s, 4 active infrared sensors for detection of distance from obstacles, a PIC16F628 microcontroller at 4MHz, and a NiMH rechargeable battery. The infrared sensors have a limited range of 2 to 3 cm, which is similar to the size of the robot itself. Since the sensor output is noisy, the less signi¯cant bit of the A/D converter is used to re-initialize every 50 ms the pseudo-random number generator required to initialise the genetic strings, add noise to the neuron thresholds, and perform genetic mutations.
The robot is asked to navigate in a 25 by 18 cm white arena with a wall in the middle.
The ¯tness is computed and accumulated at each sensory-motor cycle using a truncated version of a three-component function to evolve straight navigation and obstacle avoidance [5]  where V is the sum of the speeds of the two wheels (this component is maximized by high wheel rotation), ¢V is the absolute di®erence between the two wheel-speeds (this component is maximized by straight navigation) and i is the activity of the most active sensor (this component is maximized by distance from obstacles). Since the Alice robot  sensor value bits set 0-1 000 2-3 001 4 011 5-7 111  does not have wheel encoders to measure wheel rotation, the speed values used in the ¯tness function are taken from the motor output of the neural circuit. Motor output is a good approximation of wheel speed except for the situation when the robot is against an obstacle (in that case the actual wheel velocity is zero or signi¯cantly lower than the motor output). However, in that condition the ¯tness returns a zero value because at least one of the infrared sensors has maximum activation. The function is truncated by setting its value to zero whenever one of the wheel speeds is in backward rotation. Each of the three terms is scaled so that the maximal ¯tness value of each sensory-motor cycle multiplied by the total number of cycles in a navigation trial could ¯t in a single byte.
The network architecture is composed of 8 neurons and 8 sensory units. Since the ¯tness function returns non-zero values only for forward navigation, the infrared sensor on the back of the robot is not used. The activations of the three frontal sensors are scaled in the range [0; 7] and coded on three bits by setting active bits proportionally to the sensor activation, as shown in table V. Since the sensors tend to saturate when the robot is close to an obstacle, this bit encoding gives less precision for high sensor activation. Three sensory neurons are allocated for the front left and for the front right sensor each and two sensory neurons for the front sensor. The spiking state of each sensory neuron is given by the value of the corresponding bit using the lookup table V. Only the ¯rst two bits in the lookup table are used for the two neurons corresponding to the front sensor.
Sensors and motors are updated every 20 ms, but the spiking network is updated every 1.2 ms with the embedded R/C clock at 4 MHz. The rotation speed and direction of the  wheels is computed using the spike count of four motor neurons in push/pull mode, as for the experiments with the Khepera robot described above.
For each experiment, a population of 6 individuals was randomly initialized and evolved for 3 hours using on-board batteries. Each individual is tested for 14 seconds. Every three minutes the best ¯tness obtained so far was logged in a block of 60 bytes in the RAM and then downloaded to a computer at the end of the experiment. The graph on the left side of ¯gure 9 shows the ¯tness values of the best individuals for ¯ve experiments with di®erent random initialization of the population. A ¯tness value of 60 corresponds to a collision-free navigation for 14 seconds. Higher values are obtained by straight and faster trajectories. The best individual shown on the right side of ¯gure 9 covers the entire arena in 11 s.
All best evolved individuals perform wall following around the obstacle in the middle of the arena while maintaining a distance that generates the lowest sensor activation. Figure 10 shows the architecture of the controller corresponding to the trajectory depicted on the right side of ¯gure 9. This pattern of diagonal connectivity is found in almost all best evolved networks (with some individual variations). Neurons tend to have connections from a small set (3 on average) of neighboring sensors and from a small set (4 on average) of neighboring neurons. This pattern of connectivity loosely reminds topological sensory  maps of biological brains where neighboring neurons receive activation from neighbouring sensors [15]. This layout ensures that smooth change in sensor space translates into smooth change in neural space and that small variations in sensory stimulation (for example, due to the movement of the agent) do not cause completely di®erent patterns of neural activation.

In this article we have shown that arti¯cial evolution is a suitable method to generate functional architectures of spiking neurons by searching only through the space of neuron sign and connectivity. The Spike Response Model used in the ¯rst set of experiments contains several parameters whose values have been taken from previous literature [9] and were not optimized for this speci¯c implementation. Therefore, we cannot exclude that di®erent parameter values would make the circuits harder or easier to evolve.
The only critical modi¯cation that we made to the Spike Response Model was the insertion of noise in the refractory period. In preliminary experiments without noise, evolution stagnated very quickly into poor systems because most of the neural circuits fell into locked oscillations that were not sensitive to sensory input and ¯tness values did not increase over generations. Noise in the refractory period anticipates or delays the ¯ring time of neurons, thus decreasing the probability of locked oscillations generated by feedback loops. A similar e®ect can be obtained by adding some noise centered around zero to the  membrane thresholds. This latter option was used in the micro-controller implementation of the simple spiking neuron because it required comparatively fewer resources.
The micro-controller implementation maintains the main features of the evolutionary spiking system, such as the genetic encoding and network architecture, but it introduces major simpli¯cations in the evolutionary and neural algorithms. Although the experimental results described here are promising, we cannot exclude that the micro-controller system may have less computational abilities than the more complex model. The major di®erence between the Spike Response Model and the simpler digital model is that the former includes non-linear functions for synaptic signal transmission and refractory period.
However, it is hard to tell what environmental and/or behavioral situations require those non-linearity.
We can ¯nally compare the low-level spiking network implementation presented here, with analog VLSI implementations of comparable functionalities. It is clear that our microcontroller implementation must pay the price of programmability [2], that is, we can expect to achieve higher power consumption, lower speed and less computational parallelism than with an analog implementation that uses the same silicon resources. These drawbacks, however, have a counterbalance in the greater °exibility of a programmable implementation in the de¯nition and adaptation of the circuit topology and parameters.
In this respect, our low-level implementation, by exploiting the microcontroller parallelism and adopting an atomic representation of spikes as bits, goes in the direction of an optimal exploitation of the resources available in a programmable device. Furthermore adding learning rules into such a spiking network would require time-varying memory units. The most obvious implementation of such units in analog devices is by mean of capacitors, which are known to be space consuming and to su®er from leakage, whereas in microcontrollers it is straightforward to allocate more memory and processing resources to a run-time adaptive mechanism.

We have described a simple method to evolve functional networks of spiking neurons, a low-level e±cient implementation in microcontrollers, and experimental tests on two robot navigation problems.

These results could pave the way to two types of future developments. On the one hand, the method could be extended to study issues of information coding in networks of spiking neurons coupled to real environments. For example, one could investigate under what environmental, behavioral, and/or architectural conditions evolved spiking controllers rely on precise ¯ring time rather than on ¯ring rate. On the other hand, the micro-controller implementation could make its way in a number of embedded application that require adaptive signal processing. More than 3.5 billion microcontroller units are sold each year for embedded systems (washing machines, credit cards, car electronics, etc.), exceeding by more than an order of magnitude the number of microprocessor units sold for computers [16].

Appendix A: Micro-controller Implementation of the Spiking Network  The steps of the neuron model described above are implemented as follows: 1. Refractory period. Check state of corresponding bit in OUTPS; if set to 1, go to step 3.
2. Compute contribution of incoming spikes and membrane update. Start with spikes from sensory neurons: Increment MEMB variable by counting (left shift with carry) the number of active bits that result from the AND function of byte INPS and byte ICONN. Continue with spikes from positive neurons: Increment MEMB variable by counting the number of active bits that result from the AND function of bytes OUTPS, SIGN, and NCONN. Finish with spikes from negative neurons: Decrement MEMB variable by counting the number of active bits that result from the AND function of OUTPS and the complement (NOT function) of byte SIGN and byte NCONN. The decrement is stopped before MEMB goes below zero (which is signalled by a bit °ag in a housekeeping byte of the microcontroller; this same byte also signals over°ow, which does not occur here because there are few neurons in the network).
3. Spike generation. Compute random value for ri and check whether MEMB is equal or larger to THRES incremented/decreased by ri. If so (spike), set the corresponding bit in OUTPS to 1 and reset MEMB to zero. Otherwise (no spike), set corresponding bit in OUTPS to 0.
4. Leakage. If MEMB is greater or equal than the leaking constant ki = 1, decrement it by the leaking constant ki = 1.

The network is update synchronously, so that each neuron changes its state according to the state of all neurons computed at the previous cycle. Therefore, step 3 above updates only a temporary copy of OUTPS which is then moved into OUTPS once all neurons have been updated. Alternatively, one could update the network asynchronously by picking a neuron at random and changing directly OUTPS at step 3. Once the entire network has been updated, the array of sensory spikes INPS is updated too.
When run on a PIC16F628 using the embedded R/C oscillator running at 4MHz, the entire network is updated in approximately 1.2 ms. In some case, such as for the robotics experiment described here, the entire network can be updated faster than the time interval required to update sensors and motors (20 ms). Between new sensory values, INPS is set to all 0's while the neurons continue to be updated using only internally generated spikes.

Appendix B: Micro-controller implementation of the steady-state evolutionary algorithm  In these experiments, each individual is mutated at three locations by toggling the value of a randomly selected bit. The ¯rst mutation takes place in the SIGN byte that de¯nes the signs of the neurons. The second mutation occurs at a random location of the NCONN block that de¯nes the connectivity among neurons. The third mutation occurs at a random location of the ICONN block that de¯nes the connectivity from sensors. Mutations are performed by making an XOR operation between the byte to be mutated and a byte with a single 1 at a random location.
The population (genetic strings and ¯tness values) is stored in the EEPROM because this type of memory can be read and written by the program just like the RAM memory, but in addition it holds its contents also when the microcontroller is not powered (at least 40 years for the microcontrollers used here). Each individual occupies a continuous block of bytes where the ¯rst byte is its ¯tness and the remaining 17 bytes represent the genetic string. The very ¯rst byte of the EEPROM memory records the number of replacements made so far. Whenever the microcontroller is powered up, the main program reads the ¯rst byte of the EEPROM. If it is 0, the population is initialized, otherwise it is incrementally evolved (step 2).
EEPROM memories can be written only a limited number of times (for example, the  EEPROM of the microcontroller used here can be written/read approximately 10,000,000 times) and usage and temperature generate errors during reading/writing (bit values are toggled) that require error-checking routines. Therefore, in the experiments described here, we keep a copy of the entire population in the free space of the RAM memory and copy it to the EEPROM only at prede¯ned intervals.

This work was supported by the Swiss National Science Foundation, grant no. 620-58049. The authors thank Gilles  Caprari for help with the interface between the evolutionary spiking circuit on chip and the Alice robot.