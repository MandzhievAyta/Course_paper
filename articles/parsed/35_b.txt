Towards Autonomous Self-localization of Small Mobile Robots using Reservoir Computing and Slow Feature Analysis  Studies carried on rodents show that these animals can efﬁciently process spatial information from their environment [1]. They are able to get acquainted with a new environment and through learning its features they can construct a spatial representation of their environment (i.e., a cognitive map).
The part of the rat’s brain which is involved in this spatial representation is the hippocampus, and more speciﬁcally, areas CA1 and CA2 [1].
Intelligent autonomous navigation systems can be classiﬁed in reactive and deliberative systems. Whereas reactive systems consists of instantaneous sensory-motor mappings, deliberative systems have more abstract planning capabilities and they usually take into account the history of sensory inputs (or past events) for taking the next action. The ability of a robot to selflocalize in its environment is clearly important once it provides basic cognitive information to a deliberative navigation system.
In other words, it allows for planning and higher level cognitive behavior in the context of mobile robots as well as biological systems.
Traditional robot localization systems are designed mostly by probabilistic methods which can perform SLAM (Simultaneous Localization And Mapping) under suitable assumptions  [2] and are usually built for robots having high-resolution expensive laser scanners. Biologically inspired systems for robot localization can be considered a competitive alternative that works well for small mobile robots. Robustness, learning and low computation time are some characteristics of these biological inspired systems. Most systems are based on visual input from a camera [3]–[6] and model hippocampal place cells from rats [3]–[7].
These place cells are the main components of the spatial navigation system in rodents. Each place cell codes for a particular location of the rat’s environment, presenting a peak response in the proximities of that location (the place ﬁeld of that cell). Other components of the brain’s spatial representation system includes head-direction cells, which encode the orientation of the animal in its environment, and grid cells, which are non-localized representations of space (having a grid-like structure of activations in space) [1].
There are two classes of stimuli used by place and grid cells, namely, idiothetic and allothetic. The former corresponds to inner system signals, i.e., proprioceptive sensors such as odometry signals (e.g., from encoders), inertia sensors, etc. The latter (allothetic input) is represented by external information coming from the environment such as distance sensors, camera, touch sensors, etc. Most systems use allothetic information to correct the odometry signals from dead reckoning [3], [5]–[7].
Previous work has focused on supervised learning approaches for robot localization using solely short-range noisy distance sensors [8]. In this work, we propose a hierarchical architecture with an unsupervised learning technique which is built on the concept of slowness [9]. Our architecture is composed of three layers, where the ﬁrst layer is a randomly created recurrent neural network (the reservoir) which functions as a temporal kernel that projects the input to a high dimensional dynamic space. The second layer receives the signals from the reservoir and the input, and extracts the slow features from it using Slow Feature Analysis (SFA) [9]. The SFA layer learns to encode spatial representations of the environment which are invariant over time. The third layer performs sparse coding on the output of the SFA layer using Independent Component Analysis (ICA) [10], generating  Draft version of paper to appear in the Proceedings of the IEEE SMC 2009  localized representations of space (as the place cells from biological systems).
Similarly to [4], we use SFA to model grid cells. While they use several SFA layers and high-dimensional input from a camera, we use only few noisy distance sensors and a RC-SFA based architecture. As the reservoir weights remain ﬁxed in our RC-SFA architecture, only the upper layers learn. The reservoir concept is ﬁrst used in the form of Echo State Networks [11] and Liquid State Machines [12]. These two learning paradigms for recurrent neural networks have been recently termed under the common name of Reservoir Computing [13].
Both techniques do not train the recurrent neural network, but only a linear readout output layer (supervised learning).
As we will show in this paper, a small mobile robot (the e-puck) can learn to self-localize in real environments based solely on short-range noisy distance sensors. The main advantages of this work are ﬁve-fold: the environment is unstructured; the robot has small dimensions and only 8 shortrange distance sensors (4 cm - 30 cm); odometry information is not used; self-localization emerges from an unsupervised learning process; and the model can correct itself from kidnapping situations without any pre-design decision (the kidnapping is not seen during learning).
The proposed architecture is biologically plausible and models the place cells found in rodents. Previous work has shown the modeling of place cells with the proposed architecture only for simulated mobile robots [8]. Now we extend it to real environment settings using the e-puck robot. In addition, we show the importance of the timescale of the reservoir for learning of place cells.

Reservoir Computing (RC) is used here to model the ﬁrst layer of our architecture. The basic building block of RC is the reservoir, which is a randomly created recurrent neural network. This network is composed of sigmoidal neurons and is modeled by the following state update equation [11]:  x(t + 1) = f ((1 − α)x(t) + α(Winu(t) + Wresx(t))), (1)  where: u(t) denotes the input at time t; x(t) represents the reservoir state; α is the leak rate [14], [15]; and f () = tanh() is the hyperbolic tangent activation function (common type of activation function used in reservoirs). The connections between the nodes of the network are represented by weight matrices: Win is the connection matrix from input to reservoir and Wres represents the recurrent connections between internal nodes. The initial state of the dynamical system is x(0) = 0. A standard reservoir (without the leak rate) is found when α = 1.
The connection matrices Win and Wres are randomly generated and remain always ﬁxed (non-trainable weights).
The recurrent connections Wres are generated from N (0, 1) and rescaled such that the system is stable and the reservoir has the echo state property (i.e., it has a fading memory [11]).
This can be done by rescaling the matrix so that the spectral  radius |λmax| (the largest absolute eigenvalue) of the linearized system is smaller than one [11]. In this work, reservoir weights (Wres) are rescaled to achieve a spectral radius of |λmax| = 0.99 which is an arbitrarily chosen value which sets the reservoir to the edge of stability. The initialization of Win is given in Section III-A.

The reservoir dynamics can also be tuned to match the input signal dynamics by changing the leak rate of the reservoir α ∈ (0, 1] [14], [15]. So, low leak rates make the reservoir function in a slow timescale, effectively increasing its memory capacity but reducing its ability to respond quickly to input signals. On the other hand, leak rates close to 1 yield reservoirs with less memory to hold past stimuli but with more agile processing of the input.

RC-based systems are usually trained in a supervised way.
In these systems, the reservoir states are mapped to the desired output with a readout matrix which is usually found by standard linear regression methods on the reservoir states [13]. In this paper, we propose a RC-SFA architecture which is a hierarchical network of nodes where the lower layer is the reservoir and the upper layers are composed of SFA and ICA units, respectively (Fig. 1). The function of the reservoir is basically to expand the input signals to a highdimensional dynamic space. The randomly created reservoir can be understood as a temporal non-linear kernel which extract features from the input signal. Because of its recurrent connections, the reservoir states contain echoes of the past inputs, providing a short-term memory to our model. The SFA layer receives signals from the input nodes u(t) and from the reservoir nodes x(t). This layer learns instantaneous functions of the input which are slowing-varying or invariant representations [9] of the reservoir states. The ICA layer learns a sparse and local representation of the SFA features and is the last layer in our architecture. The following sections focus on these upper layers.

nu : number of inputs; nres: number of neurons in the reservoir; nsfa: number of SFA units; nica: number of ICA units.

Slow Feature Analysis (SFA) is an unsupervised learning method which ﬁnds instantaneous functions of the input based on the concept of slowness [9]. It is able to extract slowingvarying features of an input signal. In [16], it is shown that SFA is able to reproduce qualitative and quantitative properties of complex cells from the primary visual cortex V1. In [4], grid cells (from the entorhinal cortex of rats) and hippocampal place cells are modeled with an hierarchy of non-linear SFA layers.
The learning problem can be deﬁned as follows. Given a high-dimensional input signal x(t), ﬁnd a set of scalar functions gi(x(t)) so that the SFA output yi = gi(x(t)) varies as slowly as possible and still carries signiﬁcant information.
Mathematically, ﬁnd output signals yi = gi(x(t)) such that [9]:  where h.it and y˙ denote temporal averaging and the derivative of y, respectively.
Algorithm: As a pre-processing step, the input signal x(t) is normalized to have zero mean and unit variance. We consider the linear case gi(x) = wT x, because the input signal is already non-linearly expanded by the reservoir in the ﬁrst layer.
The SFA learning algorithm is as follows: Solve the generalized eigenvalue problem:  where A := h x˙ x˙T it and B := hxxT it.
The eigenvectors w1, w2, ..., wnsfa corresponding to the ordered generalized eigenvalues λ1 ≤ λ2 ≤ ... ≤ λnsfa solve the learning task, satisfying (3-5) and minimizing (2) (see [9] for more details). This algorithm is guaranteed to ﬁnd the global optimum.
Architecture: The SFA layer in our architecture (Fig. 1) is denoted by ysfa(t):  where: xsfa(t) is the input vector at time t consisting of a concatenation of input u(t) and reservoir states x(t). Note that the states x(t) are generated by feeding the input u(t) for t = 1, 2, ...ns in equation (1), where ns is the number of samples. The matrix Wsfa is a nsfa × (nu + nres) matrix found by solving (6). After learning, ysfa(t) generates non-localized representations of the environment, in a similar way as grid cells of the entorhinal cortex of rats [1].

Independent Component Analysis (ICA) is a method for sparse coding of an input signal as well as blind source separation [10]. The learning problem of ICA [10] can be deﬁned as follows. Assume that a linear mixture of signals x1, x2...xn can be used for ﬁnding the n independent components or latent variables s1, s2...sn. The observed values x(t) = [x1(t), x2(t)...xn(t)] can be written as:  where A is the mixing matrix; and s(t) = [s1(t), s2(t)...sn(t)] is the vector of independent components (both A and s(t) are assumed to be unknown). The vector s(t) can be generated after estimating matrix A:  where W is the inverse matrix of A. The basic assumption for ICA is that the components si are statistically independent and have nongaussian distributions [10].
Algorithm: We use the FastICA algorithm for ﬁnding W [10]. The observed vector x(t) is preprocessed by centering (zero-mean) and whitening (decorrelation and unit variance) [10]. The algorithm tries to maximize the nongaussianity of ICA neurons wx(t). A sketch of the algorithm (for one unit) is found below: 1. Initialize w randomly 2. Let w+ = E{xg(wT x)} − E{g′(wT x)w} 3. Let w = w+/kw+k 4. Do steps 2 and 3 until convergence, where g is the derivative of a nonquadratic function G (in this work, G(u) = u3) (see [10] for details). Convergence means that vectors w+ and w point in the same direction.
Architecture: The ICA output is:  where: ysfa(t) is the input vector at time t (the observed values); Wsfa is the mixing matrix (nica × nsfa); and yica(t) is the output of the ICA layer, which, in this work, learns to generate localized outputs which model hippocampal place cells of rats [1].

The robot used in the following experiments is the epuck robot [17] extended with 8 infra-red sensors which can measure distances in the range [4-30] cm (see Fig. 2). For generating datasets with recorded sensor readings, we use a robot controller written in Matlab that communicates with the e-puck through a Bluetooth link. The controller performs basic wall following in the environment and it switches randomly to left or right wall following with a certain probability ρ.
When the robot switches from right to left wall (or viceversa), it can generate ellipse-like trajectories inside a room until it ﬁnds a wall to follow (see Fig. 4). One iteration (for sensing and acting) lasts 200 ms on average. The speed of the robot is not constant. The e-puck motor actuator sets the speed (steps/second) of a stepper motor (the maximum speed  is 1000 steps per second). In this work, the actuator is limited to the interval ±[15, 385] steps/s (or ±[0.198, 5.08] cm/s).
The 8 distance sensors are sequentially read while the robot is moving (our architecture is not modeled to correct these delays between sensor readings, but instead the reservoir may autonomously solve inconsistencies involved in this process because of the memory its recurrent connections provide). The signal u(t) ∈ [0, 1] is built by recording the 8 distance sensors during robot navigation and scaling them to the interval [0, 1].

This section shows experiments with the e-puck robot in an unstructured environment with 2 rooms connected by a corridor (Fig. 3). The robot navigates in this environment according to the controller described in previous section. So, it can stay navigating in one room for a random time interval, eventually making ellipse-shaped trajectories or leaving the room towards the corridor (see Fig. 4). The randomness of the robot movement is determined by ρ (see previous section). We have made experiments with different settings (ρ = 0, ρ = 0.004, ρ = 0.008) and in all of them, place cells could be learned (the more random the movement, the more difﬁcult the place cell learning). This section shows results considering the most random behavior (ρ = 0.008).
We recorded the robot sensor readings in a dataset during 67 minutes of navigation in the environment (generating 18120 iterations of sensing-acting). The complete robot trajectory is shown in Fig. 4. For making this trajectory, we use a camera placed at the top of the environment and the ReactiVision recognition software [18] to record the position and heading of the robot during navigation. Fig. 4 also shows 25 labeled positions which partition the environment in smaller locations (strictly for analysis purposes).
In the following, we describe the initialization of parameters for the experiments in this section. The number of inputs are nu = 8 corresponding to the robot’s distance sensors. The reservoir has nres = 600 neurons. The upper layers have each 4 units (nsfa = nica = 4). The size of the SFA and ICA layers has a direct consequence on what type of place cells are learned. In [8], 70 units for each of the upper layers are used, generating around 60 place cells after learning (for a big maze).
In the current work, 4 units are used because the environment is smaller and contains only 2 rooms. The SFA layer is associated with grid cells found in the entorhinal cortex of rats [1], for instance, in the simulated rat’s experiment in [4]. As grid  Fig. 4. Trajectory (in gray) generated by the robot controller in environment from Fig. 3 for 67 minutes. Twenty ﬁve (25) labeled asterisks are manually deﬁned in this environment for analysis purposes.

cells are non-localized representation of space (they ﬁre for more than a single location) [4], [8], sparse coding is used for learning place cells (the ICA layer). Previous work [8] only uses one timescale in the reservoir. For the current experiments with a real robot, better results were achieved with a reservoir having multiple timescales (leak rates set to α1 = 0.05 for half of the reservoir and α2 = 0.15 for the other half). These settings were necessary because the current robot has a variable speed and a more random movement behavior, thus requiring a reservoir with slow-processing and fast-processing neurons (in [8], the robot speed is constant and the robot behavior less random). The matrix connecting the input to the reservoir (Win) is initialized to -2, 2 and 0 with probabilities 0.075, 0.075 and 0.85, respectively.
The RC-SFA architecture learns in steps, from the bottom SFA layer to the top ICA layer, and uses 7/8 of the input signal (15855 timesteps) as the training dataset and 1/8 (2265 timesteps) is used for testing. First, the SFA layer learns by solving (6) where the inputs are the reservoir states and distance sensors (like in (7)). After Wsfa is found, the output of SFA units ysfa(t), t = 1, 2, ..., ns is generated using (7).
Afterwards, the ICA layer learns its connections weights using the FastICA algorithm from Section II-C where the inputs for  This section shows the results after training the SFA and ICA layers with the setup presented in the previous section.
Four different SFA and ICA units are generated after learning.
We have observed that some units are most sensitive to the robot movement direction (not shown). We only show here the place cell which learned to be position invariant (see Fig. 5).
This unit could distinguish between the two rooms of the environment even though the robot could stay in one room for a random time interval and generating random movements in it. In this sense, this place cell could be used for room detection (robot localization). Fig. 5 shows the response of the place cell (ICA unit 2) as a function of the robot position in the environment (ﬁrst plot) and the place cell output over time (second plot). The colored dots represent the output of the ICA unit (where red denotes a peak response, green an intermediate response, and blue a low response). It is possible to see that this unit learned to detect in which room the robot is located, that is, high responses (red and yellow) in right room and low responses (blue) in left room.
Results on test data (trajectories unseen during learning) are shown in Fig. 6 for same ICA unit 2. It also shows that the learned place cell can distinguish between the rooms for new robot trajectories, which indicates its generalization capability.
Note that when the robot ﬁrst enters the right room, the ICA output is green for some time period until it turns to red. So, it takes some time until the unit responds with a high activity in this room.
We also tested the capability of RC-SFA architecture to recover from a kidnapping situation. For that, we used the same test dataset as in Fig. 6, but we kidnapped the robot twice at timesteps 150 and 640 and placed it back at timesteps 400 and 980 respectively. In other words, we shifted the robot from the right room to the left room and after some timesteps  Place cells − ICA activation map − Training phase unit: 2  Fig. 5. Place cell representations on training data. Dots in red denote a peak response, in green an intermediate response, and in blue a low response. Top: Response of ICA units as a function of the robot position in the environment.
Bottom: the ICA output over time. For each location (in time) given by the labeled asterisks in Fig. 3, there is a colored dot representing the ICA output.

Place cells − ICA activation map − Test phase unit: 2  from the left room to right room. The output of ICA unit 2 over time is shown in Fig. 7. It takes approximately 20 to 30 timesteps until the place cell recover itself from the kidnapping event and output a correct response. It is possible to note that the response transition of the unit is smooth despites the abrupt kidnapping event.
During the experiments, we have seen that the timescales present in the reservoir (leak rates) are very important for learning place cells. By tuning two distinct timescales in the reservoir and, in this way, empowering it with fast and slow processing neurons, we get the best performance in terms of the generated place cell. Currently, this ﬁne-tuning is performed manually (there is no automated way yet). However, by ranging over different values for the leak rates, different place cells emerge from the unsupervised learning process. For instance, by setting the leak rates to α1 = 0.11 for one half of the reservoir and α2 = 0.14 for the other half, we get a place cell which can detect the corridor of the environment. Fig. 8 shows this place cell (ICA unit 1) which presented a peak response (red) when the robot crossed the corridor, but a low response (blue) otherwise.
The experiments presented in this section were repeated for many distinct randomly generated reservoirs. In each of these  Place cells − ICA activation map − Test data unit: 1  runs, the learned place cells were qualitatively similar.

This work presented a new biologically inspired architecture  (RC-SFA) which in principle can be applied to a wide range of  applications (from speech recognition to modeling of several  aspects of intelligent robots). By using RC-SFA, the current  paper modeled place cells for autonomous learning of locations  using an e-puck robot extended with 8 longer-range (4 cm  The RC-SFA architecture is a hierarchical network com posed of an untrained and randomly generated reservoir of  recurrent neurons in the ﬁrst layer, and two upper layers which  learns by Slow Feature Analysis (SFA) [9] and Independent  Component Analysis (ICA) [10], respectively. The SFA layer  extracts the slow features from the reservoir states and distance  sensors, generating signals which are invariant to fast-varying  input signals but dependent on slowing-varying input signals.

It is in this way that the robot position in the environment  can be extracted from the distance sensors and the reservoir  states. Finally, the ICA layer, by performing sparse coding,  generates independent signals with spike-like responses for  In this work, place cells learned either to distinguish in  which room the robot was or to detect the corridor connecting  these two rooms. The type of place cell which can emerge from  the unsupervised learning process depends on two main things:  the timescales present in the reservoir; and the movement  pattern of the robot. We have also shown that the place cells  can recover nicely from kidnapping situations which are not  The advantages of the current approach include: the envi ronment is unstructured; it works for robots of small dimen sions and with cheap sensors; and no proprioceptive informa tion (odometry) is necessary for predicting the location of the  robot. This work is just a short investigation of the applications  of the RC-SFA architecture, particularly to autonomous learn ing of the self-localization ability for small robots. Future work  may be performed in modeling bigger environments with more  rooms, including dynamic environments. Additionally, it would  be very desirable to implement on-line learning techniques for  the SFA and ICA layers so that the robot could learn while it  This research is partially funded by the EC’s project OR GANIC (FP7-231267). Eric Antonelo is sponsored by the