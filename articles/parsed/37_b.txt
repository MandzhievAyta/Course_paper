The combination of computational neuroscience and embodied models are novel methodology for understanding the inner workings of the brain. There is a small, but growing, community of individual researchers and laboratories around the world that combine these fields. However, there is a need to publicize this line of research to attract more scientists to this young field. Therefore, we recently edited a book that includes many of the top researchers and laboratories around the world in Neuromorphic and Brain-Based Robotics [1]. The common theme among these researchers is that they are interested in some aspect of the brain sciences, and are using robotic devices as either an experimental tool to further our understanding of the brain, or to develop neurobiologically inspired robots. The present paper highlights some of their work to introduce the different areas of research and key issues in this transdisciplinary field. We know we have not included everyone in this paper and apologize for any omissions. However, we feel that the examples are representative of the most important areas in this line of research, and that they represent the state-ofthe-art in the field at this time. We sincerely hope their research and the ensuing discussion will inspire and attract a new generation of neuromorphic and brain-based roboticists.

Neuromorphic and brain-based robots are not encapsulated in a single field with its own journal or conference. Rather, the field crosses many disciplines, and groundbreaking neuromorphic robot research is carried out in computer science, engineering, neuroscience, and many other departments. The field is known by many names: biologically inspired robots, brain-based devices, cognitive robots, neuromorphic engineering, neurobots, neurorobots, and many more.
Arguably, the field may have begun with William Grey Walter’s turtles, created in the 1950s, whose simple yet interesting behaviors were guided by an analog electronic nervous system [2]. Another landmark was the fascinating thought experiments in the book by Valentino Braitenberg, Vehicles: Experiments in Synthetic Psychology [3].
Braitenberg’s Vehicles inspired a generation of hobbyists and scientists, present company included, to use synthetic methodology (Braitenberg’s term) to study brain, body, and behavior together. We like to think of synthetic methodology as “understanding through building” and it is certainly an apt mission statement for neuromorphic and brain-based robots [4].
It has been 90 years since the popular word “robot” first appeared in Karel Capek ’s play R.U.R. With the dawn of the twenty-first century, our expectations are high for a new scientific paradigm and a major technological advancement in the field of robotics. At the present time, robots have become prevalent in our society. Robots can be found in commercial, manufacturing, military, and entertainment applications.
We now have robotic vacuum cleaners, robotic soccer players, and autonomous vehicles on the ground, in the sky, and beneath the ocean. Because of major technical and empirical advances in the brain sciences over the last few decades, the time appears right for integrating the exciting fields of robotics and neuroscience. This promising area of research, which we term neuromorphic and brain-based robotics, may generate the paradigm shift for truly intelligent machines.
Robots are increasing our productivity and quality of life in industry, defense, security, entertainment, and household chores. However, the behavior of these robots pales compared with that of animals and insects with nervous systems. Biological organisms survive in dynamic environments and display flexibility, adaptability, and survival capabilities that far exceed any artificial systems. Neuromorphic and brainbased robotics are exciting and emerging research fields that investigate the roots of biological intelligence by embodying models of the brain on robotic platforms.
Moreover, because neuromorphic and brain-based robots follow a working model (i.e.
the biological brain and body), we believe this field will lead to autonomous machines that we can truly call intelligent.
Neuromorphic and brain-based robots are physical devices whose control system has been modeled after some aspect of brain processing. Because the nervous system is so closely coupled with the body and situated in the environment, brain-based robots can be provide powerful tools for studying neural function. Brain-based robots can be tested and probed in ways that are not yet achievable in human and animal experiments.
The field of neuromorphic and brain-based robots is built on the notion that the brain is embodied in the body and the body is embedded in the environment.
In the real biological nervous system, this embodiment mediates all sensations, governs motion, is crucial for higher order cognition, and notions of self. The question of how our mind is constructed from physical substrates such as the brain and body are still a mystery. A synthetic approach occupies an important position in investigating  how complex systems, such as the brain, give rise to intelligent behavior through interactions with the world. The concept is highlighted by “embodiment” in the fields of robotics, artificial intelligence, and cognitive science. It argues that the mind is largely influenced by the state of the body and its interaction with the world [4].
The neuromorphic and brain-based robotic approaches can provide valuable heuristics for understanding how the brain works both empirically and intuitively.
Neurologists analytically investigate whether the brain is healthy or impaired due to neurological disorders. Neuroscientists probe different areas of the brain to determine which brain regions are necessary for a specific function. By using a synthetic methodology, neurobiologically inspired robots can constructively exhibit how the brain works through its interaction with the body, the environment, and other agents in real world situations.
The remainder of this paper is divided into logical sections starting with physical robotic platforms, progressing to case studies using brain-based robots, to philosophical considerations with future brain-based robots, and finally important ethical issues as robots become so intelligent that we have to think about the mental state of the robots.

2. Neuromorphic robots: biologically and neurally inspired designs  In this section, we directly consider how the body of a robot affects thinking and cognition. The interaction of neuromorphic robots with the environment enhances information processing and leads to morphological computation [4]. Many lessons remain to be learned through the construction of ingenious biomimetic devices.

2.1. Robust haptic recognition by an anthropomorphic robot hand  To achieve human-like stable manipulation and robust recognition, Koh Hosoda of Osaka University has constructed an anthropomorphic robot hand, called a Bionic Hand, which is covered with soft silicon skin and equipped with distributed tactile receptors [5]. Because of its compliance, the Bionic Hand can realize stable grasping with an object and gather rich sensory information through manipulation. It has the ability to reproduce the exploratory behavior of human hands and could be a powerful tool for understanding object manipulation and haptic recognition. Because the hand has so many touch receptors, small changes in the position and orientation of a manipulated object lead to large changes of the somatosensory pattern. The Bionic Hand is compliant and through repetitive grasping different objects settle into a unique and stable position in the hand. Because it shares many physical features of the human hand, the Bionic Hand can recognize different object classes, based on the discriminating pattern of touch sensor activity, by this repetitive grasping scheme.

2.2. Biomimetic robots based on the rat whisker system  Rats are endowed with prominent facial whiskers, which they use to explore the environment immediately surrounding their head. This tactile sense is considered to be primary in rats in the way vision is primary in primates – to the untrained eye the behavior of blind rats can appear indistinguishable from that of sighted animals.
Neurobiology has shown us that the brain nuclei and circuits that process vibrissal touch signals and that control the positioning and movement of the whiskers, form a  neural architecture that is a good model of how the mammalian brain, in general, coordinates sensing with action. Therefore, a research group at Sheffield University has been building robot whisker systems as a significant step towards building the first robot mammal [6]. In particular, they have designed and developed two whiskered robot platforms, Whiskerbot and SCRATCHbot, in order to better understand the rat whisker system, and to test hypotheses about whisker control and vibrissal sensing in a physical brain-based device. Each platform includes sophisticated mechanical, electronic, and software components, in which they must make trade-offs made between biomimetic ideals and engineering practicalities. By combining high-speed videos of real rat whisking, detailed computation neural simulations, biomimtetic whiskers and hair follicles, and embodied models of whisking, they suggest that rat locomotion and whisking might be viewed as a series of orients, with the focus of attention being constantly shifted, often ahead of the animal.

3. Brain-based robots: architectures and approaches  Several groups have designed control architectures for robots based on some aspects of the nervous system. The reason is twofold; first, using neurobiology as inspiration for robotic control systems may lead to better robot design, and second, using synthetic methodology, these embodied neural models may lead to a better understanding of brain and cognitive function.

Krichmar and Cox presented a strategy for controlling autonomous robots, which was based on the principles of neuromodulation in the mammalian brain [7].
Neuromodulatory systems signal important environmental events to the rest of the brain causing the organism to focus its attention on the appropriate object, ignore irrelevant distractions, and respond quickly and appropriately to the event [8]. There are separate neuromodulators that alter responses to risks, rewards, novelty, effort, and social cooperation. Moreover, the neuromodulatory systems provide a foundation for cognitive function in higher organisms; attention, emotion, goal-directed behavior, and decision-making derive from the interaction between the neuromodulatory systems and brain areas, such as the amygdala, frontal cortex, and hippocampus. They used a robot, whose behavior was controlled by a neural model of the cholinergic, dopaminergic, and serotonergic systems, to test the hypothesis that neuromodulatory activity can shape learning, drive attention, and select actions. The robot learned to approach stimuli that were predictive of positive value and move away from stimuli that were predictive of negative value. These experiments suggest a mechanism of how neuromodulatory systems influence attention and decision-making. The robot’s controller may be a design strategy for controlling autonomous systems based on the principles of neuromodulation found in the mammalian brain.

A group of roboticists and computational neuroscientists at the University of Queensland and Queensland University of Technology, have sought to build a system that captures the desirable properties of the rodent’s method of navigation into a system  that is suitable for practical robot navigation [9]. The core model, dubbed RatSLAM, has demonstrated that it can construct maps of large and complex areas from very weak geometric information, and it can build, maintain, and use maps simultaneously over extended periods of time. RatSLAM is a visual simultaneous localization and mapping algorithm. But its map construction and path integration are achieved in a neural architecture inspired by grid and place cells found in the rodent entorhinal cortex and hippocampus. RatSLAM has been shown to 1) map a complete suburb from a single webcam mounted on a car, 2) navigate in an active office environment for two weeks, and 3) share a lexicon to describe places with two robots, each with a uniquely grounded RatSLAM representation of space.

As brain-based and neuromorphic robots become more sophisticated, the possibility of truly intelligent machines is becoming a reality. Rather than programming in all the knowledge a system needs to operate, scientists are looking to child development for inspiration in creating intelligent robots. Learning algorithms based on the sensorimotor space and interactions with the environment may allow robots to develop body plans and fluid movements, as well as serve as a means to study our own development [10]. Minoru Asada of Osaka University recently presented a framework for cognitive developmental robots that focuses on the mirror neuron system for social cognitive development and the development of a sense of self and others [11].
As an alternative to the developmental approach, Wagatsuma of the Kyushu Institute of Technology has turned to dynamical systems to build neuromorphic robots.
Brain oscillations and neural pattern generators are prevalent in the vertebrate brain.
Wagatsuma uses a synthetic approach, with embodied systems that emulate the brain’s oscillatory dynamics, to explore a phase coding scheme between the amygdala, hippocampus, and prefrontal cortex [12]. Such dynamic patterns are thought to contribute to cognitive functions such as motor coordination, episodic memory, and consciousness.
It could be said that the ultimate goal of autonomous robotics is machine consciousness. A group at The Neurosciences Institute, which is led by Nobel laureate Gerald Edelman, has been studying consciousness for a number of years [13]. Based on their prior work with brain-based devices, they recently presented a case for how to construct a conscious artifact, and how to test if the artifact is indeed conscious [14].

We feel strongly that the brain-based and neuromorphic approach will transform the field of autonomous robots to the point where we will have robots in our society that have the adaptability and intelligence that we attribute to biological systems. We believe that neuromorphic and brain-based robotics will provide the groundwork for the development of intelligent machines, contribute to our understanding of the brain and mind, as well as how the nervous system gives rise to complex behavior.
Neuromorphic and brain-based robotics is an exciting field of research that has a growing community of researchers with a wide range of multidisciplinary talents and backgrounds.

If and when roboticists are able to create a truly intelligent and sentient machine, there are philosophical and ethical issues to consider. Bekey from the University of Southern California and his colleagues Lin and Abney from California Polytechnic State University have been studying the ethical implications of intelligent robots and the urgency of this issue [15]. Isaac Asimov’s three laws of robotics fail when applied to current military, healthcare, and other social robots. They propose a hybrid approach toward achieving robot morality, in which robots learn from experience how best to fulfill its roles, as well as know that certain roles are morally mandated for it, or are morally illegitimate and hence morally forbidden.
The fact that Neuromorphic and Brain-based Robotics covers such a wide range of topics shows how unexplored this young field is at the present time. These intelligent, brainy robots of the future will one day, very soon, be interacting and cooperating with human society. We strongly believe this research approach will advance science and society in positive and prosperous ways that we can only now imagine.